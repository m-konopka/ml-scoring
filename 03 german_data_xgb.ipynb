{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c5b2905abcbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcategory_encoders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTargetEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWOEEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequentialFeatureSelector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from shutil import copyfile\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from category_encoders import TargetEncoder, WOEEncoder\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    RepeatedStratifiedKFold,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.set_printoptions(formatter={\"float\": lambda x: \"{0:0.4f}\".format(x)})  # `easy numbers` mode\n",
    "pd.set_option(\"display.max_columns\", None)                                # `show whole df` mode\n",
    "warnings.filterwarnings(\"ignore\")                                         # `do not disturbe` mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>present_resid</th>\n",
       "      <th>age</th>\n",
       "      <th>n_credits</th>\n",
       "      <th>n_people</th>\n",
       "      <th>chk_acct_A11</th>\n",
       "      <th>chk_acct_A12</th>\n",
       "      <th>chk_acct_A13</th>\n",
       "      <th>chk_acct_A14</th>\n",
       "      <th>purpose_A40</th>\n",
       "      <th>purpose_A41</th>\n",
       "      <th>purpose_A410</th>\n",
       "      <th>purpose_A42</th>\n",
       "      <th>purpose_A43</th>\n",
       "      <th>purpose_A44</th>\n",
       "      <th>purpose_A45</th>\n",
       "      <th>purpose_A46</th>\n",
       "      <th>purpose_A48</th>\n",
       "      <th>purpose_A49</th>\n",
       "      <th>saving_acct_A61</th>\n",
       "      <th>saving_acct_A62</th>\n",
       "      <th>saving_acct_A63</th>\n",
       "      <th>saving_acct_A64</th>\n",
       "      <th>saving_acct_A65</th>\n",
       "      <th>present_emp_A71</th>\n",
       "      <th>present_emp_A72</th>\n",
       "      <th>present_emp_A73</th>\n",
       "      <th>present_emp_A74</th>\n",
       "      <th>present_emp_A75</th>\n",
       "      <th>sex_A91</th>\n",
       "      <th>sex_A92</th>\n",
       "      <th>sex_A93</th>\n",
       "      <th>sex_A94</th>\n",
       "      <th>other_debtor_A101</th>\n",
       "      <th>other_debtor_A102</th>\n",
       "      <th>other_debtor_A103</th>\n",
       "      <th>property_A121</th>\n",
       "      <th>property_A122</th>\n",
       "      <th>property_A123</th>\n",
       "      <th>property_A124</th>\n",
       "      <th>other_install_A141</th>\n",
       "      <th>other_install_A142</th>\n",
       "      <th>other_install_A143</th>\n",
       "      <th>housing_A151</th>\n",
       "      <th>housing_A152</th>\n",
       "      <th>housing_A153</th>\n",
       "      <th>job_A171</th>\n",
       "      <th>job_A172</th>\n",
       "      <th>job_A173</th>\n",
       "      <th>job_A174</th>\n",
       "      <th>telephone_A191</th>\n",
       "      <th>telephone_A192</th>\n",
       "      <th>foreign_A201</th>\n",
       "      <th>foreign_A202</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     present_resid  age  n_credits  n_people  chk_acct_A11  chk_acct_A12  \\\n",
       "0                4   67          2         1             1             0   \n",
       "1                2   22          1         1             0             1   \n",
       "2                3   49          1         2             0             0   \n",
       "3                4   45          1         2             1             0   \n",
       "4                4   53          2         2             1             0   \n",
       "..             ...  ...        ...       ...           ...           ...   \n",
       "995              4   31          1         1             0             0   \n",
       "996              4   40          1         1             1             0   \n",
       "997              4   38          1         1             0             0   \n",
       "998              4   23          1         1             1             0   \n",
       "999              4   27          1         1             0             1   \n",
       "\n",
       "     chk_acct_A13  chk_acct_A14  purpose_A40  purpose_A41  purpose_A410  \\\n",
       "0               0             0            0            0             0   \n",
       "1               0             0            0            0             0   \n",
       "2               0             1            0            0             0   \n",
       "3               0             0            0            0             0   \n",
       "4               0             0            1            0             0   \n",
       "..            ...           ...          ...          ...           ...   \n",
       "995             0             1            0            0             0   \n",
       "996             0             0            0            1             0   \n",
       "997             0             1            0            0             0   \n",
       "998             0             0            0            0             0   \n",
       "999             0             0            0            1             0   \n",
       "\n",
       "     purpose_A42  purpose_A43  purpose_A44  purpose_A45  purpose_A46  \\\n",
       "0              0            1            0            0            0   \n",
       "1              0            1            0            0            0   \n",
       "2              0            0            0            0            1   \n",
       "3              1            0            0            0            0   \n",
       "4              0            0            0            0            0   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "995            1            0            0            0            0   \n",
       "996            0            0            0            0            0   \n",
       "997            0            1            0            0            0   \n",
       "998            0            1            0            0            0   \n",
       "999            0            0            0            0            0   \n",
       "\n",
       "     purpose_A48  purpose_A49  saving_acct_A61  saving_acct_A62  \\\n",
       "0              0            0                0                0   \n",
       "1              0            0                1                0   \n",
       "2              0            0                1                0   \n",
       "3              0            0                1                0   \n",
       "4              0            0                1                0   \n",
       "..           ...          ...              ...              ...   \n",
       "995            0            0                1                0   \n",
       "996            0            0                1                0   \n",
       "997            0            0                1                0   \n",
       "998            0            0                1                0   \n",
       "999            0            0                0                1   \n",
       "\n",
       "     saving_acct_A63  saving_acct_A64  saving_acct_A65  present_emp_A71  \\\n",
       "0                  0                0                1                0   \n",
       "1                  0                0                0                0   \n",
       "2                  0                0                0                0   \n",
       "3                  0                0                0                0   \n",
       "4                  0                0                0                0   \n",
       "..               ...              ...              ...              ...   \n",
       "995                0                0                0                0   \n",
       "996                0                0                0                0   \n",
       "997                0                0                0                0   \n",
       "998                0                0                0                0   \n",
       "999                0                0                0                1   \n",
       "\n",
       "     present_emp_A72  present_emp_A73  present_emp_A74  present_emp_A75  \\\n",
       "0                  0                0                0                1   \n",
       "1                  0                1                0                0   \n",
       "2                  0                0                1                0   \n",
       "3                  0                0                1                0   \n",
       "4                  0                1                0                0   \n",
       "..               ...              ...              ...              ...   \n",
       "995                0                0                1                0   \n",
       "996                0                1                0                0   \n",
       "997                0                0                0                1   \n",
       "998                0                1                0                0   \n",
       "999                0                0                0                0   \n",
       "\n",
       "     sex_A91  sex_A92  sex_A93  sex_A94  other_debtor_A101  other_debtor_A102  \\\n",
       "0          0        0        1        0                  1                  0   \n",
       "1          0        1        0        0                  1                  0   \n",
       "2          0        0        1        0                  1                  0   \n",
       "3          0        0        1        0                  0                  0   \n",
       "4          0        0        1        0                  1                  0   \n",
       "..       ...      ...      ...      ...                ...                ...   \n",
       "995        0        1        0        0                  1                  0   \n",
       "996        1        0        0        0                  1                  0   \n",
       "997        0        0        1        0                  1                  0   \n",
       "998        0        0        1        0                  1                  0   \n",
       "999        0        0        1        0                  1                  0   \n",
       "\n",
       "     other_debtor_A103  property_A121  property_A122  property_A123  \\\n",
       "0                    0              1              0              0   \n",
       "1                    0              1              0              0   \n",
       "2                    0              1              0              0   \n",
       "3                    1              0              1              0   \n",
       "4                    0              0              0              0   \n",
       "..                 ...            ...            ...            ...   \n",
       "995                  0              1              0              0   \n",
       "996                  0              0              1              0   \n",
       "997                  0              0              0              1   \n",
       "998                  0              0              0              0   \n",
       "999                  0              0              0              1   \n",
       "\n",
       "     property_A124  other_install_A141  other_install_A142  \\\n",
       "0                0                   0                   0   \n",
       "1                0                   0                   0   \n",
       "2                0                   0                   0   \n",
       "3                0                   0                   0   \n",
       "4                1                   0                   0   \n",
       "..             ...                 ...                 ...   \n",
       "995              0                   0                   0   \n",
       "996              0                   0                   0   \n",
       "997              0                   0                   0   \n",
       "998              1                   0                   0   \n",
       "999              0                   0                   0   \n",
       "\n",
       "     other_install_A143  housing_A151  housing_A152  housing_A153  job_A171  \\\n",
       "0                     1             0             1             0         0   \n",
       "1                     1             0             1             0         0   \n",
       "2                     1             0             1             0         0   \n",
       "3                     1             0             0             1         0   \n",
       "4                     1             0             0             1         0   \n",
       "..                  ...           ...           ...           ...       ...   \n",
       "995                   1             0             1             0         0   \n",
       "996                   1             0             1             0         0   \n",
       "997                   1             0             1             0         0   \n",
       "998                   1             0             0             1         0   \n",
       "999                   1             0             1             0         0   \n",
       "\n",
       "     job_A172  job_A173  job_A174  telephone_A191  telephone_A192  \\\n",
       "0           0         1         0               0               1   \n",
       "1           0         1         0               1               0   \n",
       "2           1         0         0               1               0   \n",
       "3           0         1         0               1               0   \n",
       "4           0         1         0               1               0   \n",
       "..        ...       ...       ...             ...             ...   \n",
       "995         1         0         0               1               0   \n",
       "996         0         0         1               0               1   \n",
       "997         0         1         0               1               0   \n",
       "998         0         1         0               0               1   \n",
       "999         0         1         0               1               0   \n",
       "\n",
       "     foreign_A201  foreign_A202  \n",
       "0               1             0  \n",
       "1               1             0  \n",
       "2               1             0  \n",
       "3               1             0  \n",
       "4               1             0  \n",
       "..            ...           ...  \n",
       "995             1             0  \n",
       "996             1             0  \n",
       "997             1             0  \n",
       "998             1             0  \n",
       "999             1             0  \n",
       "\n",
       "[1000 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data\\\\german_data.csv\", sep=\",\", na_values=\"NULL\")\n",
    "\n",
    "X = df.drop(\n",
    "    [\n",
    "        \"GOOD\",\n",
    "        \"BAD\",\n",
    "        \"duration\",\n",
    "        \"credit_his\",\n",
    "        \"amount\",\n",
    "        \"installment_rate\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "X = pd.get_dummies(X)\n",
    "y = df[\"GOOD\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-25 23:58:22,915]\u001b[0m A new study created in memory with name: no-name-0e2e94b8-38ad-402d-8be1-eb4fb5dbc583\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MAX_ROUNDS = 1000\n",
    "CV_SPLITS = 10\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "SEED = 42\n",
    "\n",
    "auc_monit = 0.5\n",
    "\n",
    "\n",
    "def objective(trial, build_name):\n",
    "    global auc_monit\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-8, 1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 14),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 50),\n",
    "        \"gamma\": trial.suggest_uniform(\"gamma\", 0, 10),\n",
    "        \"reg_alpha\": trial.suggest_uniform(\"reg_alpha\", 0, 10),\n",
    "        \"reg_lambda\": trial.suggest_uniform(\"reg_lambda\", 0, 10),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.3, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.3, 0.9),\n",
    "        \"colsample_bylevel\": trial.suggest_uniform(\"colsample_bylevel\", 0.3, 0.9),\n",
    "        \"colsample_bynode\": trial.suggest_uniform(\"colsample_bynode\", 0.3, 0.9),\n",
    "        \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 1, 10),\n",
    "        \"scale_pos_weight\": trial.suggest_int(\"scale_pos_weight\", 1, 8)\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"test-auc\")\n",
    "    xgb_cv_results = xgb.cv(\n",
    "        params=param,\n",
    "        dtrain=dtrain,\n",
    "        stratified=True,\n",
    "        nfold=CV_SPLITS,\n",
    "        num_boost_round=MAX_ROUNDS,\n",
    "        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "        verbose_eval=False,\n",
    "        seed=SEED,\n",
    "        callbacks=[pruning_callback],\n",
    "    )\n",
    "\n",
    "    n_estimators = len(xgb_cv_results)\n",
    "    param[\"n_estimators\"] = n_estimators\n",
    "    trial.set_user_attr(\"n_estimators\", n_estimators)\n",
    "\n",
    "    mean_train_auc = xgb_cv_results[\"train-auc-mean\"].values[-1]\n",
    "    mean_val_auc = xgb_cv_results[\"test-auc-mean\"].values[-1]\n",
    "\n",
    "    if mean_val_auc > auc_monit:\n",
    "        auc_monit = mean_val_auc\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%H%M%S\")\n",
    "        snapshot_name = f\"T{timestamp} {trial.number:01d} [{np.round(mean_train_auc * 2 - 1, 3)} {np.round(mean_val_auc * 2 - 1, 3)}].json\"\n",
    "        json.dump(param, open(os.path.join(\"Builds\", build_name, snapshot_name), \"w\"))\n",
    "\n",
    "    return mean_val_auc * 2 - 1\n",
    "\n",
    "\n",
    "BUILD_NAME = datetime.now().strftime(\"%Y%m%d_T%H%M%S\") + \"_German_data_init\"\n",
    "os.mkdir(os.path.join(\"Builds\", BUILD_NAME))\n",
    "\n",
    "study = optuna.create_study(directions=[\"maximize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-25 23:58:38,851]\u001b[0m Trial 2 finished with value: 0.0 and parameters: {'learning_rate': 5.014888017771435e-06, 'max_depth': 9, 'min_child_weight': 2, 'gamma': 3.574163202853504, 'reg_alpha': 1.4760892262013925, 'reg_lambda': 8.565952765661105, 'subsample': 0.7748251895679228, 'colsample_bytree': 0.31438580837583024, 'colsample_bylevel': 0.6876855058346889, 'colsample_bynode': 0.7847934727088888, 'max_delta_step': 9, 'scale_pos_weight': 7}. Best is trial 2 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:43,440]\u001b[0m Trial 3 finished with value: 0.4974289999999999 and parameters: {'learning_rate': 0.045934422783925594, 'max_depth': 6, 'min_child_weight': 17, 'gamma': 0.5282732996555473, 'reg_alpha': 6.80275090444281, 'reg_lambda': 1.0339896945200966, 'subsample': 0.4746765735873432, 'colsample_bytree': 0.5443518298447005, 'colsample_bylevel': 0.8225715456757081, 'colsample_bynode': 0.6084787216336915, 'max_delta_step': 8, 'scale_pos_weight': 6}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:46,208]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'learning_rate': 7.3863330760979e-05, 'max_depth': 7, 'min_child_weight': 12, 'gamma': 3.9749777489411087, 'reg_alpha': 6.197784605353086, 'reg_lambda': 9.401547823075493, 'subsample': 0.4215283076688675, 'colsample_bytree': 0.7207483448847827, 'colsample_bylevel': 0.48574993593993665, 'colsample_bynode': 0.872134436580164, 'max_delta_step': 1, 'scale_pos_weight': 8}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:46,342]\u001b[0m Trial 0 finished with value: 0.40361880000000006 and parameters: {'learning_rate': 0.0012457030636800375, 'max_depth': 6, 'min_child_weight': 31, 'gamma': 3.7900554744460235, 'reg_alpha': 4.737031910153097, 'reg_lambda': 8.246344029544495, 'subsample': 0.46666345264381026, 'colsample_bytree': 0.48104003563011877, 'colsample_bylevel': 0.43124629207525483, 'colsample_bynode': 0.5713825840661444, 'max_delta_step': 2, 'scale_pos_weight': 4}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:46,423]\u001b[0m Trial 1 finished with value: 0.42985720000000005 and parameters: {'learning_rate': 0.0003643153260562561, 'max_depth': 3, 'min_child_weight': 6, 'gamma': 1.807711702921424, 'reg_alpha': 2.042759851990499, 'reg_lambda': 4.922930086404998, 'subsample': 0.8257244152389478, 'colsample_bytree': 0.6827945212078607, 'colsample_bylevel': 0.3558740418375179, 'colsample_bynode': 0.4854079526850005, 'max_delta_step': 5, 'scale_pos_weight': 4}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:46,601]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:46,860]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:48,602]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:49,465]\u001b[0m Trial 4 finished with value: 0.45195240000000014 and parameters: {'learning_rate': 0.0034144949623256785, 'max_depth': 11, 'min_child_weight': 6, 'gamma': 6.975512350479596, 'reg_alpha': 3.7648645771270637, 'reg_lambda': 7.974961439815502, 'subsample': 0.803593683705998, 'colsample_bytree': 0.6238656034718435, 'colsample_bylevel': 0.5747621548873058, 'colsample_bynode': 0.38832133554229764, 'max_delta_step': 8, 'scale_pos_weight': 4}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:49,660]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:52,740]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 74.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:54,103]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 74.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:54,432]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:57,395]\u001b[0m Trial 6 finished with value: 0.4683807999999998 and parameters: {'learning_rate': 1.1159170595066257e-05, 'max_depth': 5, 'min_child_weight': 41, 'gamma': 9.514524092387823, 'reg_alpha': 8.716627065684573, 'reg_lambda': 0.8958119926718289, 'subsample': 0.470370844285504, 'colsample_bytree': 0.6529991607296908, 'colsample_bylevel': 0.5924230772542693, 'colsample_bynode': 0.43699709955596544, 'max_delta_step': 7, 'scale_pos_weight': 4}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:57,611]\u001b[0m Trial 8 finished with value: 0.46357139999999997 and parameters: {'learning_rate': 0.0014569654541720992, 'max_depth': 2, 'min_child_weight': 18, 'gamma': 3.206459080863586, 'reg_alpha': 1.1065032714579948, 'reg_lambda': 3.3446238850924495, 'subsample': 0.4309802396802941, 'colsample_bytree': 0.7921120214433464, 'colsample_bylevel': 0.791160143669293, 'colsample_bynode': 0.4532058095767863, 'max_delta_step': 5, 'scale_pos_weight': 4}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:58,086]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:58:58,812]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:04,453]\u001b[0m Trial 16 finished with value: 0.46966660000000005 and parameters: {'learning_rate': 0.015812114946875483, 'max_depth': 11, 'min_child_weight': 23, 'gamma': 8.737311833737472, 'reg_alpha': 4.167840582196662, 'reg_lambda': 2.5020094424874353, 'subsample': 0.7268936036976963, 'colsample_bytree': 0.6146921189184338, 'colsample_bylevel': 0.7374907604603484, 'colsample_bynode': 0.6998551725930962, 'max_delta_step': 7, 'scale_pos_weight': 3}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:05,541]\u001b[0m Trial 19 finished with value: 0.4639998000000003 and parameters: {'learning_rate': 6.414852405050091e-06, 'max_depth': 4, 'min_child_weight': 50, 'gamma': 0.5273260664528588, 'reg_alpha': 8.16160540475168, 'reg_lambda': 1.3037624595756316, 'subsample': 0.5487829892311289, 'colsample_bytree': 0.64705915937282, 'colsample_bylevel': 0.6738991176491493, 'colsample_bynode': 0.6704382466793466, 'max_delta_step': 10, 'scale_pos_weight': 6}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:05,802]\u001b[0m Trial 20 finished with value: 0.4769998000000002 and parameters: {'learning_rate': 0.01984824743778899, 'max_depth': 10, 'min_child_weight': 24, 'gamma': 0.29457086304939784, 'reg_alpha': 7.670519547849967, 'reg_lambda': 0.7610946718932906, 'subsample': 0.537838396785885, 'colsample_bytree': 0.6337127773568308, 'colsample_bylevel': 0.6548472791548555, 'colsample_bynode': 0.5108965077504409, 'max_delta_step': 10, 'scale_pos_weight': 6}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:05,944]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 20.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:06,203]\u001b[0m Trial 14 finished with value: 0.46680960000000016 and parameters: {'learning_rate': 0.009586107886881237, 'max_depth': 12, 'min_child_weight': 17, 'gamma': 8.260650269044136, 'reg_alpha': 9.882406798378623, 'reg_lambda': 0.7689521585341375, 'subsample': 0.678025816333278, 'colsample_bytree': 0.5474170762276201, 'colsample_bylevel': 0.873267308442853, 'colsample_bynode': 0.7087393691455199, 'max_delta_step': 7, 'scale_pos_weight': 6}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:06,395]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:06,584]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:06,774]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:06,831]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:07,178]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:07,273]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:10,846]\u001b[0m Trial 31 finished with value: 0.4973808000000002 and parameters: {'learning_rate': 0.007967196941930288, 'max_depth': 9, 'min_child_weight': 31, 'gamma': 0.18729814338158396, 'reg_alpha': 7.799200933759961, 'reg_lambda': 0.15151419629632823, 'subsample': 0.49885121526269155, 'colsample_bytree': 0.49341970593567225, 'colsample_bylevel': 0.6397675596847702, 'colsample_bynode': 0.7389026400982924, 'max_delta_step': 10, 'scale_pos_weight': 3}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:11,020]\u001b[0m Trial 27 finished with value: 0.4620000000000002 and parameters: {'learning_rate': 0.9545617304116787, 'max_depth': 12, 'min_child_weight': 12, 'gamma': 1.592331534537549, 'reg_alpha': 2.7851693795078876, 'reg_lambda': 0.20623919760937126, 'subsample': 0.59855145566784, 'colsample_bytree': 0.6038601291483592, 'colsample_bylevel': 0.6646806533057632, 'colsample_bynode': 0.6227976453203373, 'max_delta_step': 9, 'scale_pos_weight': 7}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:11,351]\u001b[0m Trial 30 finished with value: 0.4797619999999998 and parameters: {'learning_rate': 0.0002610464480773923, 'max_depth': 9, 'min_child_weight': 32, 'gamma': 0.03625060453372131, 'reg_alpha': 3.0389748428947, 'reg_lambda': 0.39756074108922324, 'subsample': 0.6097121495625436, 'colsample_bytree': 0.4977133886766807, 'colsample_bylevel': 0.6345508388808208, 'colsample_bynode': 0.7351978120159879, 'max_delta_step': 10, 'scale_pos_weight': 3}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:14,213]\u001b[0m Trial 24 finished with value: 0.48304760000000013 and parameters: {'learning_rate': 0.04794056864712171, 'max_depth': 13, 'min_child_weight': 26, 'gamma': 1.3683166139870555, 'reg_alpha': 6.690313696001069, 'reg_lambda': 0.23504205063533334, 'subsample': 0.5595665228262038, 'colsample_bytree': 0.5872459126007552, 'colsample_bylevel': 0.7818246965506663, 'colsample_bynode': 0.5128861007525792, 'max_delta_step': 8, 'scale_pos_weight': 5}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:16,265]\u001b[0m Trial 34 finished with value: 0.48223820000000006 and parameters: {'learning_rate': 0.0030195480889871084, 'max_depth': 7, 'min_child_weight': 30, 'gamma': 0.37168735585005663, 'reg_alpha': 0.08634937987658375, 'reg_lambda': 0.5276352632582558, 'subsample': 0.502914297941936, 'colsample_bytree': 0.49863561665115824, 'colsample_bylevel': 0.54138856394934, 'colsample_bynode': 0.7416639899719891, 'max_delta_step': 10, 'scale_pos_weight': 3}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:17,426]\u001b[0m Trial 33 finished with value: 0.4733335999999999 and parameters: {'learning_rate': 0.003124180655633428, 'max_depth': 7, 'min_child_weight': 33, 'gamma': 0.02369870847984773, 'reg_alpha': 7.966257012348132, 'reg_lambda': 0.8118452263909113, 'subsample': 0.5161939288851141, 'colsample_bytree': 0.4982687412405998, 'colsample_bylevel': 0.5192596707675345, 'colsample_bynode': 0.545253095070025, 'max_delta_step': 10, 'scale_pos_weight': 3}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:17,721]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:17,887]\u001b[0m Trial 32 finished with value: 0.48023799999999994 and parameters: {'learning_rate': 0.003315219456883186, 'max_depth': 7, 'min_child_weight': 31, 'gamma': 0.21865913009602644, 'reg_alpha': 7.923476572426542, 'reg_lambda': 0.1919079766040701, 'subsample': 0.500719076645814, 'colsample_bytree': 0.471683103758196, 'colsample_bylevel': 0.5609555291676558, 'colsample_bynode': 0.7383456112890059, 'max_delta_step': 10, 'scale_pos_weight': 3}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:18,627]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:18,895]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:19,180]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:21,344]\u001b[0m Trial 35 finished with value: 0.49066680000000007 and parameters: {'learning_rate': 0.0003730806550626035, 'max_depth': 7, 'min_child_weight': 29, 'gamma': 0.038833532797631215, 'reg_alpha': 5.9954400575120905, 'reg_lambda': 0.02754919674515749, 'subsample': 0.4905846965811499, 'colsample_bytree': 0.4846759618147924, 'colsample_bylevel': 0.5444900783193511, 'colsample_bynode': 0.753884160967326, 'max_delta_step': 10, 'scale_pos_weight': 3}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:21,624]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:23,905]\u001b[0m Trial 36 finished with value: 0.47619060000000024 and parameters: {'learning_rate': 0.0037605501062708407, 'max_depth': 7, 'min_child_weight': 30, 'gamma': 2.0590366890648957, 'reg_alpha': 0.20431136889943155, 'reg_lambda': 1.6934570169557563, 'subsample': 0.5017563316507794, 'colsample_bytree': 0.48181137535388235, 'colsample_bylevel': 0.5364159020604987, 'colsample_bynode': 0.8277933882540829, 'max_delta_step': 10, 'scale_pos_weight': 2}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:25,497]\u001b[0m Trial 38 finished with value: 0.4939047999999999 and parameters: {'learning_rate': 0.004893810272655296, 'max_depth': 6, 'min_child_weight': 34, 'gamma': 1.1440884672129865, 'reg_alpha': 6.083330457729302, 'reg_lambda': 0.07673382318671272, 'subsample': 0.48030864379716787, 'colsample_bytree': 0.4820530621053587, 'colsample_bylevel': 0.5456831297653766, 'colsample_bynode': 0.7511841485701831, 'max_delta_step': 8, 'scale_pos_weight': 5}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:25,773]\u001b[0m Trial 44 finished with value: 0.4884287999999999 and parameters: {'learning_rate': 0.006348446457270248, 'max_depth': 8, 'min_child_weight': 34, 'gamma': 0.6416828705905624, 'reg_alpha': 5.863036208069684, 'reg_lambda': 0.0269246167818101, 'subsample': 0.5095666415248992, 'colsample_bytree': 0.393384006774641, 'colsample_bylevel': 0.5120287781504779, 'colsample_bynode': 0.650087711538976, 'max_delta_step': 9, 'scale_pos_weight': 4}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:26,055]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:26,323]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:26,615]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:26,889]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:27,132]\u001b[0m Trial 42 finished with value: 0.4864761999999998 and parameters: {'learning_rate': 0.00014411638111322124, 'max_depth': 6, 'min_child_weight': 21, 'gamma': 0.7095014418366135, 'reg_alpha': 5.981897212161678, 'reg_lambda': 0.01922875686370129, 'subsample': 0.42564944344853084, 'colsample_bytree': 0.3815947621451885, 'colsample_bylevel': 0.897864745500854, 'colsample_bynode': 0.8864818812770939, 'max_delta_step': 5, 'scale_pos_weight': 4}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:27,283]\u001b[0m Trial 51 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:27,552]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:27,961]\u001b[0m Trial 53 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:28,436]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:30,187]\u001b[0m Trial 46 finished with value: 0.48042819999999997 and parameters: {'learning_rate': 3.589877199159145e-05, 'max_depth': 8, 'min_child_weight': 34, 'gamma': 1.0194106586706062, 'reg_alpha': 5.021015767658724, 'reg_lambda': 0.11556133859802062, 'subsample': 0.43470183102406024, 'colsample_bytree': 0.39287059916642336, 'colsample_bylevel': 0.5813509767992832, 'colsample_bynode': 0.7855976428721174, 'max_delta_step': 8, 'scale_pos_weight': 5}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:30,484]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:32,660]\u001b[0m Trial 45 finished with value: 0.48890480000000003 and parameters: {'learning_rate': 4.075894375295787e-05, 'max_depth': 8, 'min_child_weight': 34, 'gamma': 0.675266353782347, 'reg_alpha': 5.055281520972222, 'reg_lambda': 0.011109802910813704, 'subsample': 0.525089134027292, 'colsample_bytree': 0.39496195839443426, 'colsample_bylevel': 0.5015793572351648, 'colsample_bynode': 0.7759211574907278, 'max_delta_step': 9, 'scale_pos_weight': 3}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:32,925]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:33,304]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:33,584]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:33,866]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:34,248]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:35,006]\u001b[0m Trial 54 finished with value: 0.48909500000000006 and parameters: {'learning_rate': 5.391150022988844e-05, 'max_depth': 5, 'min_child_weight': 21, 'gamma': 1.8007822171835102, 'reg_alpha': 6.009451595463545, 'reg_lambda': 0.03652862571676499, 'subsample': 0.4611563004360932, 'colsample_bytree': 0.36006234558781036, 'colsample_bylevel': 0.5066191173387575, 'colsample_bynode': 0.8824818217745454, 'max_delta_step': 4, 'scale_pos_weight': 4}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:35,767]\u001b[0m Trial 56 finished with value: 0.49147620000000014 and parameters: {'learning_rate': 4.019074876795152e-05, 'max_depth': 6, 'min_child_weight': 8, 'gamma': 0.381339371801062, 'reg_alpha': 5.28931909178817, 'reg_lambda': 0.015329835665695006, 'subsample': 0.42593685596742004, 'colsample_bytree': 0.5235380553513507, 'colsample_bylevel': 0.8912995988356084, 'colsample_bynode': 0.7105884266999651, 'max_delta_step': 4, 'scale_pos_weight': 5}. Best is trial 3 with value: 0.4974289999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:36,219]\u001b[0m Trial 66 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:36,733]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:39,147]\u001b[0m Trial 58 finished with value: 0.5007620000000002 and parameters: {'learning_rate': 0.0224091278336908, 'max_depth': 4, 'min_child_weight': 15, 'gamma': 0.4466824410134913, 'reg_alpha': 5.259216413382591, 'reg_lambda': 0.02666329333744274, 'subsample': 0.5280837828746587, 'colsample_bytree': 0.4245121066221338, 'colsample_bylevel': 0.8980941640144151, 'colsample_bynode': 0.8902255509949913, 'max_delta_step': 5, 'scale_pos_weight': 5}. Best is trial 58 with value: 0.5007620000000002.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:40,426]\u001b[0m Trial 65 finished with value: 0.479714 and parameters: {'learning_rate': 6.352536988310619e-05, 'max_depth': 4, 'min_child_weight': 28, 'gamma': 0.01965331810939286, 'reg_alpha': 5.915159319302843, 'reg_lambda': 0.0017754187648211378, 'subsample': 0.4950580387676651, 'colsample_bytree': 0.45956670044820047, 'colsample_bylevel': 0.5194148964434984, 'colsample_bynode': 0.8064160962749078, 'max_delta_step': 3, 'scale_pos_weight': 3}. Best is trial 58 with value: 0.5007620000000002.\u001b[0m\n",
      "\u001b[32m[I 2021-04-25 23:59:40,621]\u001b[0m Trial 64 finished with value: 0.4820476 and parameters: {'learning_rate': 9.93030643856892e-05, 'max_depth': 7, 'min_child_weight': 32, 'gamma': 0.6791943393770509, 'reg_alpha': 5.860801684172406, 'reg_lambda': 0.01042523447515152, 'subsample': 0.40797220701537174, 'colsample_bytree': 0.3235179334701683, 'colsample_bylevel': 0.8573943845557302, 'colsample_bynode': 0.8451340965127278, 'max_delta_step': 5, 'scale_pos_weight': 4}. Best is trial 58 with value: 0.5007620000000002.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Builds\\\\20210425_T235822_German_data_init\\\\study.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRIALS = None\n",
    "TIME_OUT = 60 * 15  # minutes\n",
    "N_JOBS = -1\n",
    "\n",
    "try:\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, BUILD_NAME),\n",
    "        n_trials=TRIALS,\n",
    "        timeout=TIME_OUT,\n",
    "        n_jobs=N_JOBS,\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    joblib.dump(study, os.path.join(\"Builds\", BUILD_NAME, \"study.pkl\"))\n",
    "\n",
    "joblib.dump(study, os.path.join(\"Builds\", BUILD_NAME, \"study.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD_NAME = \"20210425_T232957_German_data_init\"\n",
    "# study = joblib.load(os.path.join(\"Builds\", BUILD_NAME, \"study.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5007620000000002]\n",
      "{'learning_rate': 0.0224091278336908, 'max_depth': 4, 'min_child_weight': 15, 'gamma': 0.4466824410134913, 'reg_alpha': 5.259216413382591, 'reg_lambda': 0.02666329333744274, 'subsample': 0.5280837828746587, 'colsample_bytree': 0.4245121066221338, 'colsample_bylevel': 0.8980941640144151, 'colsample_bynode': 0.8902255509949913, 'max_delta_step': 5, 'scale_pos_weight': 5, 'n_estimators': 88}\n"
     ]
    }
   ],
   "source": [
    "N = 58\n",
    "param = study.trials[N].params\n",
    "param[\"n_estimators\"] = study.trials[N].user_attrs[\"n_estimators\"]\n",
    "\n",
    "print(study.trials[N].values)\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(**param, eval_metric=\"auc\")\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)\n",
    "scores = cross_validate(\n",
    "    model, X, np.ravel(y), scoring=\"roc_auc\", cv=cv, return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINI train: 0.598\n",
      "GINI dev: 0.502 (0.042)\n"
     ]
    }
   ],
   "source": [
    "mean_train_auc = scores[\"train_score\"].mean()\n",
    "mean_test_auc = scores[\"test_score\"].mean()\n",
    "std_test_auc = scores[\"test_score\"].std()\n",
    "print(\"GINI train:\", np.round(mean_train_auc * 2 - 1, 3))\n",
    "print(\"GINI dev:\", np.round(mean_test_auc * 2 - 1, 3), f\"({np.round(std_test_auc, 3)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None,\n",
       "              colsample_bylevel=0.8980941640144151,\n",
       "              colsample_bynode=0.8902255509949913,\n",
       "              colsample_bytree=0.4245121066221338, eval_metric='auc',\n",
       "              gamma=0.4466824410134913, gpu_id=None, importance_type='gain',\n",
       "              interaction_constraints=None, learning_rate=0.0224091278336908,\n",
       "              max_delta_step=5, max_depth=4, min_child_weight=15, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=88, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None,\n",
       "              reg_alpha=5.259216413382591, reg_lambda=0.02666329333744274,\n",
       "              scale_pos_weight=5, subsample=0.5280837828746587,\n",
       "              tree_method=None, validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:   18.5s finished\n",
      "\n",
      "[2021-04-26 00:06:03] Features: 1/25 -- score: 0.671904761904762[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:   14.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
      "\n",
      "[2021-04-26 00:06:18] Features: 2/25 -- score: 0.7031904761904761[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:   14.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.7s finished\n",
      "\n",
      "[2021-04-26 00:06:33] Features: 3/25 -- score: 0.7178333333333333[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   15.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.1s finished\n",
      "\n",
      "[2021-04-26 00:06:50] Features: 4/25 -- score: 0.7230000000000001[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:   17.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    1.2s finished\n",
      "\n",
      "[2021-04-26 00:07:08] Features: 5/25 -- score: 0.7331904761904762[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   16.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.1s finished\n",
      "\n",
      "[2021-04-26 00:07:26] Features: 6/25 -- score: 0.7371190476190477[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:   15.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    1.3s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    2.5s finished\n",
      "\n",
      "[2021-04-26 00:07:44] Features: 7/25 -- score: 0.7381666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:   17.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    1.6s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    2.8s finished\n",
      "\n",
      "[2021-04-26 00:08:05] Features: 8/25 -- score: 0.7456190476190476[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   16.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    2.6s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    2.6s finished\n",
      "\n",
      "[2021-04-26 00:08:24] Features: 9/25 -- score: 0.7490238095238095[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:   16.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:    2.9s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    3.7s finished\n",
      "\n",
      "[2021-04-26 00:08:45] Features: 10/25 -- score: 0.7538809523809523[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:   18.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.3s finished\n",
      "\n",
      "[2021-04-26 00:09:08] Features: 11/25 -- score: 0.7537857142857142[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:   19.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    4.3s finished\n",
      "\n",
      "[2021-04-26 00:09:32] Features: 12/25 -- score: 0.7545000000000001[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:   19.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    5.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    5.5s finished\n",
      "\n",
      "[2021-04-26 00:09:58] Features: 13/25 -- score: 0.7560476190476191[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   18.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    6.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    6.6s finished\n",
      "\n",
      "[2021-04-26 00:10:23] Features: 14/25 -- score: 0.7552142857142858[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:   18.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    7.2s finished\n",
      "\n",
      "[2021-04-26 00:10:49] Features: 15/25 -- score: 0.7584523809523811[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:   18.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    7.0s finished\n",
      "\n",
      "[2021-04-26 00:11:14] Features: 16/25 -- score: 0.7574523809523811[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:   18.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    7.2s finished\n",
      "\n",
      "[2021-04-26 00:11:40] Features: 17/25 -- score: 0.7547619047619047[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   17.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    8.3s finished\n",
      "\n",
      "[2021-04-26 00:12:06] Features: 18/25 -- score: 0.7548809523809523[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   19.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    8.9s finished\n",
      "\n",
      "[2021-04-26 00:12:43] Features: 18/25 -- score: 0.7566428571428573[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   18.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    8.7s finished\n",
      "\n",
      "[2021-04-26 00:13:11] Features: 19/25 -- score: 0.757357142857143[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:   17.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    9.6s finished\n",
      "\n",
      "[2021-04-26 00:13:39] Features: 20/25 -- score: 0.7569047619047619[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:   17.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.7s finished\n",
      "\n",
      "[2021-04-26 00:14:06] Features: 21/25 -- score: 0.7575952380952382[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:   17.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:   11.4s finished\n",
      "\n",
      "[2021-04-26 00:14:35] Features: 22/25 -- score: 0.7573809523809523[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:   16.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:   12.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:   11.6s finished\n",
      "\n",
      "[2021-04-26 00:15:17] Features: 22/25 -- score: 0.7575000000000001[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:   16.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:   12.2s finished\n",
      "\n",
      "[2021-04-26 00:15:58] Features: 22/25 -- score: 0.7611428571428572[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:   15.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:   10.9s finished\n",
      "\n",
      "[2021-04-26 00:16:25] Features: 23/25 -- score: 0.7571428571428571[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   15.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:   11.9s finished\n",
      "\n",
      "[2021-04-26 00:16:52] Features: 24/25 -- score: 0.7562857142857142[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:   17.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   11.9s finished\n",
      "\n",
      "[2021-04-26 00:17:22] Features: 25/25 -- score: 0.7574285714285713"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "sfs = SequentialFeatureSelector(\n",
    "    model,\n",
    "    k_features=20,\n",
    "    forward=True,\n",
    "    floating=True,\n",
    "    scoring=\"roc_auc\",\n",
    "    verbose=2,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "sfs = sfs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAABPiklEQVR4nO2deZwcVbX4v6f3nj07WUnYRUQ0AeTnAgEXcAHkwRNEBBVxeYCCoCCIiPBQEVSUJw9BELeICrwgyKIQcGEJQbYE2UII2SfrbL1Wnd8fVZ30dKp7eibTk56Z8/18aqar6t6q03Wr77n33HvPEVXFMAzDMEoJ7WwBDMMwjPrEFIRhGIYRiCkIwzAMIxBTEIZhGEYgpiAMwzCMQExBGIZhGIGYgjAGFRHpEpHdqkg3U0RURCJDIddQICLLROS9NbjuAhE5vQbX/bOInDrY1/Wv/QERubMW1x4ItXjfROQsEfnuYF2vHjEFUSeIyLtE5J8iskVENorIP0TkwJ0tVyWCKi5VbVLVpYNw7WUikvIVTmGbsqPX3VmIyDQR+aOIrPfL+HkROW0I73+piPyq+JiqHqWqv6jRLa8AvjNYF6v0/AZS+fvvbrrk/bqrn2L9DDhZRCb2M9+wwRREHSAiLcCfgB8DY4GpwLeAzM6Uqw74iK9wCtuq/mSuVe9kgNf9JfAGsCswDjgFWDuYctULfsOmVVUfG8TL1uL5nVnyfn0kKFFQeYtIRFXTwJ+BT+6gHPWLqtq2kzdgDrC5jzSfBl4ANgH3AbsWnXsf8G9gC/AT4GHgdP/cpcCvitLOBBSI+PutwE3AamAlcDkQ9s+dBvwd+L5/39eAo/xzVwAOkAa6gJ/4xxXYw//8IeBfQAfej/vScnIEfN9lwHsDjseBHwKr/O2HQNw/dxiwAvgasAavUnkY+A///Dv9e37I3z8CeNr/vDvwILABWA/8GmgrkedrwLN4ijuCV0m97ue5qJzMfv4u4IAK5fsO4J/AZuAZ4LCicwsK5VnFu/Bm4AFgI14F+nXgSCAL5Hw5nim9Ll5j8WL/+6wDbsWr5IvL6lRguf98LqrwXS4Bbiza/xbwY/9zFOgGrvL3k3jv0Ng+3v+yz8+XSf00XcAhQBjvvV0PLAX+i97vfa9nWnK9oPfoUuAPwK/w3ufCczsZeGhn1yG12qwHUR+8BDgi8gsROUpExhSfFJFj8H7oxwETgL8Bv/XPjQdux/txjwdexasIq+UWIA/sAbwNeD9QbDY6GHjRv/b3gJtERFT1Il+OQivszIBrd+O1rtrwlMUXROTYfsgWxEV4lekBwFuBg/C+e4Fd8HphuwJn4CmIw/xzh+JVFu8p2n/Y/yzAlcAU4E3AdLxKoZiT/O/RBuwF/BRPSUzBa9VOqyD3Y8B1InKiiMwoPiEiU4G78ZTzWOA84I8iMqH0In28C83AX4B7fZn2AP6qqvcC/w38zi+rtwbId5q/zQV2A5rwGhvFvAvYG0+xXiIibyrzXd+C984UKC6DA/Eq3UIZHAK8qKoby1yrQNnnV3StNv/7PQp8Fvgw3js9Bzi+j+uXUvoeARyDpyTa8BoQ4CnqoOc5MtjZGso2b8OrlG7Ba7nkgfnAJP/cn4HPFKUNAT14L+8ngceKzol/jT57EMAkvNZwsuj8SfgtIrwK45Wicw1+3l38/QWUtMIo6kEEfMcfAj8olaNM2mV4rcHN/nanf/xV4INF6T4ALPM/H4bXUk4UnT8CeNb/fC+e8nvM338YOK7M/Y8F/lUiz6eL9i8B5hXtN/r3LteDGINnk1+M1/N6GjjQP/c14Jcl6e8DTi19zn28CycVy1xyvV7vQcB1/wp8sejc3ng9jkhRWU0rOv8EcGKZez0AfL5ov9BLGAdcgKfgVuApoW8B11bx+6j0/LZ7l/B6g8UyvJ/texA9Re/XZuDbFd6jS4FHAuTaE3BqVS/s7M16EHWCqr6gqqep6jRgP7wW4A/907sCPxKRzSKyGc98IHhjFVPwzDeF62jxfh/sitflX1107f8Figfd1hRdu8f/2FTNxUXkYBF5SETaRWQL8Hm8nki1HKuqbf52rH9sCp4ZpMDr/rEC7erZhgs8CuwlIpPweh23AtP9ntdBwCO+rJNEZJ6IrBSRDjxTQqmsxc+19Ll345maAlHVTap6gaq+GU8xPw3cKSKCVw4nFMrAL4d3AZMDLlXpXZiOp0AHQtBzLTQiCqwp+txD+fdgE9Bc2FHVFPAkXo/tPXiK+Z94Pd3iXlxZ+nh+5b5PcXm9HpDm7KL3q01Vv1F0rvQ9guDfVTOeaXdEYgqiDlHVf+P1JvbzD70BfK7kZU6q6j/xxg6mF/L6P5jpRZfrxmv5F9il6PMbeD2I8UXXbfF/hFWJ2sf53+D1hKaraitwPV5ltiOswqskC8zwjwXK5Cu1RcCXgOdVNYtXOZ0LvKqq6/2k/+3nfYuqtgCfCJC1+Nqlz70Br4XcJ/49v49XiY3FK4dflpRvo6oGzQKq9C68gWceCrxtH2IFPdc8AxsIfhbPBFfMw8DheCafhf7+ByhS0tUS8PyCvluv8sH7Pv26TZXH3oQ3ZjQiMQVRB4jIPiLyFRGZ5u9PxzMXFGaBXA9cKCJv9s+3isgJ/rm7gTeLyHH+bIuz6a0EngbeIyIzRKQVuLBwQlVXA/cDV4tIi4iERGR3ETm0StHXUr5CAq91tVFV0yJyEPDxKq9bid8CF4vIBL8XcAlea78SDwNnsq2luqBkvyBrF7DFHxM4v49r/gH4sD89OQZcRoXfk4h8V0T2E5GIP1bwBTzz3QZf/o/4awfCIpIQkcMK70MJld6FPwGTReTLIhIXkWYROdg/txaYKSLlZPwtcI6IzBKRJraNWeT7eA5B3IPXMyjmYTxz6BJfSS/AM/e9pqrtfV2wj+fXDrj0fhdvA872p8eOwTNt1YJD8cx+IxJTEPVBJ95g8OMi0o2nGJ4HvgKgqncA3wXm+eaP54Gj/HPrgRPw7LMb8Gyi/yhcWFUfAH6H16pbhFeJFPNJIAYswTMN/IFg00YQPwKOF5FNInJtwPkvApeJSCdeRX5bldetxOV45opngeeAp/xjlXgYTwE8UmYfPFv42/HMBXfjDfyXRVUX482M+Q1ea3UTnl29HA3AHXi27qV4rfWj/Wu9gTcA+nW8yu4NPAW13e+zj3ehE29G20fwzEEv4w06A/ze/79BRJ4KkO/neLN1HsGbrZYGzqr0DMqhqk/hKdqDiw7/E28sovDMl/j3KJj4ZvhrEcq19Cs9vx68WXX/8E1v78Bbo3AfXuv+KYLL8ycl6yAW9ed7ikgC+CBQq7UkOx3xB1qMEYSILMAbkLxxZ8tijE5E5P14g97H7mxZaoWInIVnPv3qzpalVowYNweGYdQPqno/nvlyxKKqP97ZMtQaMzEZhmEYgZiJyTAMwwjEehCGYRhGICNmDGL8+PE6c+bMAefv7u6msbGxZumHKo/JNTLkGkgek8vkGgiLFi1ar6rbuXUBRo6rjdmzZ+uO8NBDD9U0/VDlMbn6l6de5RpIHpOrf3lGu1wFgCd1Z7jaEJEjReRFEXlFRLZbqCIiPxCRp/3tJd91QOHc90RksYi8ICLXVlhSbxiGYdSAmpmYRCQMXIe3cGcFsFBE5qvqkkIaVT2nKP1ZeMvwEZH/h+enZX//9N/xViwuqJW8hmEYRm9q2YM4CG8p/FL1ltbPw1stWo6T8N0W4/k8SeCt8I3jOZQbkcFVDMMw6pWaTXMVkeOBI1X1dH//FOBgDYgbICK74rmXmKaqjn/s+3i+WgQvGM1FAfnOwPfVPmnSpNnz5s0bsLxdXV00NVXlpHRA6Ycqj8k1MuQaSB6Ty+QaCHPnzl2kqnMCT5YbnNjRDS9AR3FUqVPwo44FpP0afsQpf38PPH84Tf72KPDuSvezQeqhu8dA8phctc9jcvUvz2iXqwA7aZB6Jb3d7U7zjwVxItvMSwAfxQvq0qWqXXjeEg+piZSGYRhGILVUEAuBPX33wTE8JTC/NJGI7IMXLerRosPLgUN9175RvAHqF2ooq2EYhlFCzRSEen7kz8RzufsCcJuqLhaRy0Tk6KKkJ+KFbiweDPkDXmSs5/Dc9T6jqnfVSlbDMAxje2q6klpV78ELHlJ87JKS/UsD8jnA52opm2EYRn9IZfPkHJdUNk8yNmKcUFTEfDEZhmFUwHFdVm3s5rnXN5LLuzy3fCOrNnXjuO7OFq3mjA41aBiGMQA6UlmWreskk3NobYixKSS0JmOs3NDN+o40Myc009IQ29li1gxTEIZhGCVk8w4rNnTT3pGiMR6lrTG+9VwoJLQ1xsnmHV5YuYkJLUmmjWskFgnvRIlrgykIwzAMH1VlQ2ea19u7ABjTGKecG7hYJMyYxhCbuzNs7EozY3wz41sShEaQ2zhTEIZhGHiD0MvaO+nsydGcjBIJ9z1EKyI0J2M4rsuydR2s70ix64RmGhPRIZC49tggtWEYo5rCIPTzr28km3MZ0xSvSjkUEw6FGNOUIO8qz7+xkTfWd5F3hv8gtvUgDMMYtXT0ZFnW7g1CtzTECIV2zDyUjEWIR8Os3dzD+s4UMyc0D5KkweQdl2zexa2RTz1TEIYxAkjnHPKOZz9PRMPEo+F+t4JHOq4qmZxDJufQk8mTznmDzKWD0DtKSITWxji5vMvLq7eQyuZ5cdVmktEwiViEWCRENBwiEg4RjYT6HLNQVXKOSy7vksl7sndn8qQy3roMFNJZB1d10Mc/TEEYxjDFcV06erKs3ZKioydHNu+wdG0HiucCORoJ0ZKI0piMei3bSJhYJFR20HUkkXdcMjmHdM6hO52jM5UjlXU8Z6DimYTQyoPQO0o04pmdNoqQy7ukMnkcN43jKiIgCIoSjYRIRsPEoxESsTCOq6zvSG1VBD3ZPK6rXhAEIOIrmEQsQqPf42mvyTcwBWEYwwpVpTuTZ0NnmvaONKpKIhpmTFOcTf70ywKO69KVybOpO4uriiCIQFMiQmMiSlMiiqte7yMcEkIihHfQxDIY5B3PZNLRkwW21ove5wBTSuFQ3lGWrtlCZzpPNu9sPR/1W+otDdFeyqBdGBJlKUDc79UF4bheDyGdy7Kh01Nsr63r3Cp3UyK602ZGmYIwjBpQMGf0ZPJ0pLKkcw6vreugIR4hEfXMDLFIyGvJVkE657C5O8OazT1kcy7RSIjmRLSizTwcCpGMhUgWreNyVcnlXdZtSbN6Uw/pbJ7nXt/QK180HCIcEqK+fJ45RDyTSDiE6yrZvDOo8/4zOYfOVJYNXWk6enKksw4vrtoMeBVsQS2IbFMIvc94axe6MnlikRAN8eFTtYVDQji07VmuL1H0O5Ph8xQNo45xXJdU1qE7k2NLd5bOVM7zqQ9bK9KOnhwbOzN+a96r2gotxMZ4hGQsQjQSIhYJE/XHDzZ2plnX4ZmQRKAxEaUxPvAplCGRXq3ZjSWVkRcHABxVr2Wbz9OjnmJxXcVVJZ1zeHrZBhLRMG0NMVoaYiRiEeL9MF+pKj3ZPJ2pLO0dadJZZ2tLu7Uhtp1c1bAxJKPGR9JQYU/TMAZANu+Qynqt3i3dWXqyeVCQkBCPhGhK9jYLCAS2avOO6/UyerI4rt8aVoiEQ/Rk8ry6tmOrCWkoEPHMUCHKV/QbQ8KYxjh5x2VjV4a1W1IAREKeGae1IUbSV3jFz8Bxle5Mjs1dGTZ0Zsi7LiERErFw3bSYjd6YgjBGJapKoT7O5h1c12sxO35L2XGVvOuSdzyTTN71ZpHkHZeebJ5nl21AFcLhEPFoaMAVXMSfzVKK4yrhOjI1BFEqu6cA8mzqyqBaWEQWIee4vLpmC5u6s6gqkXCIZDxMODQyFpONZExBGCOGbN4h77is3NiN47hbzSSO4/93tx1zfe3Qk/Eqe2Dr7J+CVTskQsgfvA2J54MnEg4R9qcx1pJ6GCzuL2HfxFMw8xTGO3J5l650nubkzhtsNQaGKQhjRNCTyfPy6s1k8y7rtqQQvBZsSLaZTSLhENGCCcWvqDaGal/Zj1YK4x3hkAyrQWNjG1ZqxrBnU1eaV9d2Eo94s2+aRogfHMPY2ZiCMIYtqsrqTT28sb6L5obY1pk/hmEMDqYgjGFJ3nFZ1t7Jxs40bU1xs20bRg0wBWEMO9LZPC+v2eJ73kzsbHEMY8RiCsIYVmzpzvDKmg4i4dCIDvVoGPWAKQhjWKCqrN2S4vV1nTQloyMyvKNh1BumIIy6x3Fdlrd3sa4jTVtjfId99huGUR027cOoOapK3vF846/Y0MX6jhRberL0ZDyvm0EeOgtkcg4vrtzMhs40Yxp3PKCLYQyE+bdHOezAZo76wOEcdmAz828fHVOpa9qDEJEjgR8BYeBGVf1OyfkfAHP93QZgoqq2+edmADcC0/EWt35QVZfVUl5j8Cm0/rN5l1Q2T1c61zsUo4KEPId28WiYZCy81dup4ypLVmxEsMVsxs5j/u1RLj4/STrlNU5WrRQuPj8JwNHH5XamaDWnZgpCRMLAdcD7gBXAQhGZr6pLCmlU9Zyi9GcBbyu6xK3AFar6gIg0AcM/wOsoI5t3eGXNFnrS+a1uGILQrZ5DvaAqedeLc5DJeS6lbbzB2JlcdXliq3IokE4J11yZMAWxAxwEvKKqSwFEZB5wDLCkTPqTgG/6afcFIqr6AICqdtVQTqMG9GTyvLR6M6rQ2hhnQ4W0IuLHG6BXUJWNITHlYOw0XnkpxI3/E2ftmmCz5qqVQjYLsRE8mU4q2X936MIixwNHqurp/v4pwMGqemZA2l2Bx4BpquqIyLHA6UAWmAX8BbhAVZ2SfGcAZwBMmjRp9rx58wYsb1dXF01NTTVLP1R56kEux/Va/wVfSACZdA/xREO/7jEUeepVrv7kefCvk7jl5t1pb08wYUKa0z71KocfsXanyzWU9xhMuRYvbuW23+3K449NIB53CIWUVCq4LT1pUoqTT3mNI45YQzgcXJcOyfNK9dDS0tyvPAXmzp27SFXnBJ2rl1lMJwJ/KFIAEeDdeCan5cDvgNOAm4ozqeoNwA0Ac+bM0cMOO2zAAixYsID+5O9v+qHKszPlUlXWbUmxbF0nk5MxopFtcyCWPv8ku+0X+A6WZSjy1Ktc1eaZf3uUa6/dZh9fty7Jtde+mYnTd6vK/DEan/H826Ncc2WC1auEyVOUcy9M8+Fjczz0QISfXRfnqScjtI1xOesraU4+LcvfH45w8fnhXmamRFI55VMZHv17lGu+vy933rk3X/5qmvd/ME9pkMCheF4vP7uQ9xx66KB7FKjlLKaVeAPMBab5x4I4Efht0f4K4GlVXaqqeeBO4O21ENIYHBxXeb29k2XrOmltjPdSDkbtuObKYPv4lZcmeO3VENlMcL56nZVTa7kKA86rVoZQFVatDHHhOUneM6eZL3yqkXVrQ3zj8hQLFnZy1lcyjB2nHH1cjsuvSjFlqouIMmWqy+VXpTj/4gx//HM3P76xGxE4+4xG/uOoJh55KILq0Dzjwj0+fNQRzJoJv/714F6/lj2IhcCeIjILTzGcCHy8NJGI7AOMAR4tydsmIhNUtR04HHiyhrIaO0DOcXltbQebu7OMaYoPSSB4AxY/G2LVyuBnvWF9iA+8uxkRZdIuyvRdXabNcJk23aV9nXD7bTGymdrOytnWUj98a0u90vUHOluoP/e5+r+3V6i5nLBxPVz9kx6OOjpHJKBWPPq4HEcfl9uudS8CH/hgnvd+oIv5t0f58dUJTj+5kVm7O6xcEarpMy59XsuXwxlneOdOPnlQblE7BaGqeRE5E7gPb5rrz1V1sYhcBjypqvP9pCcC87RoMMQfhzgP+Kt4tc0i4Ge1ktUYOOlsnpdXbyGbd4csLOZwor+VZF9ks3D/3VF++fMY/1oUQcSLIV3K+Aku51+cZsXyEG8sD7FieYh//i3CujWC6vZKZbBn5ZSr7F0HDnl3nvXrhPXrQ6xfJ7S3e/9v+00ssDd08XlJ/vlIhJZWpalZaW5Rmv3/zz0T5pafxXtVxBeek+SBeyKMm6BsWB9ifbuwYb2wvj1EV2ewQnUc+MgOfPdwGD56Qo4PHZPjD7+NcdlFCVx3++9y1eUJPnRMjnDA3Iu+3pWeHli2NMSypWGWLQ3xvz+Ob/e8enrgoouGgYIAUNV7gHtKjl1Ssn9pmbwPAPvXTDhjh+lIZXl51RaiEfOLFMRgtogP/n95fverGL/7VYz2dSF2neVw0WUpEgnlim8mt7OPX/DNYEWUScP+u7cEKolVK4X//XGcDx2bZdr0HZu88v2Alno6JXz1S0kIiHfd3KKkU8HXSqfhn3+L0NkpdHf13TvN5YT77onR2uYybrwyfoKy734O4yfkueP3UTo7tjd/Tp4yOJN1YjH4+KlZvvX1YCeSa9eE2G9mCxMnKZOnuEya7DJ5irJhvXDPXVFy2W3vygXnJPnjvCiKsOzVEGtWl8odLPPy5YPyVYD6GaQ26ghVRaGoZeq1UrXofN5VXlixiaaE+UUKomMLXHlpcCV5xSUJdp3lsstkl/ETtFdrMkipfPVLSdRfBXToEXk+8akU7zp022BosoHtBl3LKaB4wqsMg0xT0RhcfWWCq69M8PYD83zkozmO+kiOseN0q2zlWribNwlPPh7micciLHw0wppV5Svyb30nxfgJLhMmKuMnuowfrySScNiBzYFyTZmqLFjYCXgt/e4u6OwUOjuEo9/XBAHKTkRZuKRzu+P7v83p9XzBU6jnXpguK+9AKPeMW9tcTvpkljWrQ6xZFeKFxWEefCBEJr192nxOeOwfEfZ/m8PB78yz2+4uM3dzmLmby8xZLkcdGvy8ZswYvO9hCmKU05XOkco6PPnqukBTRQER2eoSQ/BcYExriBEunbIxgilXQXZ1wZLnwjz/bJjnn/H+L1taXmlu2hjihA95U4TDYWXCRGWXKS67TFb+tiCynVJxHaGxSbnzvi52nbX9etFy9vFynHthOrCSvPyqFG+bk+dPd8a46/Yo3/p6ksu/keCdh+aZOs3ljttipNNFppxzk9zx+yjr20O89II36BuLK2+b7dDcrHQGmHOmTFVO+mS2X3IVV97hMLS0QkurAsqUMhVxuR5BQaFVq1AHSrnv8o3Lt7+XKuwzLbhXB/D7P3VXfY+GBrjiikH4Aj6mIEYpriprNnvR2ARoScb6Nbi8ISR1pRwGMiC6owOoX/tSku9elmB9+za7/uQpLm/e3+GjJ+S49aYYG9Zv/4wmTPRmwaxZHWLNatnamnzxhRDdZZaE9nQTqBwGQl+V5BfOzvD5szK8+EKIu+6IcvedMR55cPsZOLms8M9HIhzyrjxfOj/HgYfkeesBDrH49s8L+m6pD6TyrkapBN2nPwp1IPTnu4iU73FUMn2V3mP6dPjv/5ZBG38AUxCjknTOYenaLXSn87Q1xNksDOuZR0GV90XnJenqgg8dnSMcgXDIa32GwnDP/0W5+Ksl6b+S5JWXQuz9Jpf17UL7OmH9uhDt7d7/F18IbTfo6DhCZwec9ZUM+73VYb/9HcZP2PaDnjrdDay8vnZJmrnvywd+l3JmlsGykRfoq5IUgX32ddln3wxfuTDDPtNbAk05ALf8rifw+tD/lnp/K++h6hEMhP58l4EouuJ7vPzsQo58/xEMti9LUxCjCFVlQ1eG19Z2EIuEaRshDvCC1gJk0sKlFzRw6QXVXSOTEa6/dtvAYjSq3gDnRG+s4IXFwb2lTAbOPDd4scFQtYhrTShEv005MDQt9aG8Ty2pV0VnCmKUkHNc3ljfRXtHipZkjEi4fsxDO8ILi8uvBQDl699K4zjg5MFxBdeBH10VJ2gmDaLc81AX4ycorW1KcadqoC37kdIirkfFNdKoR0VnCmIU0JnK8eraLTiOMqZxZCxkS6fgJz+Ic9NP44RC4AaY56dMVU777PYDor//TSx4tswUZY+9gu38Q1lB1mNFUa+Ky6gtI6MZaQTiuMrKDV0seWMjkZC3VmEkKId//i3Mh49o4oafJPjoCTkuvTJFItm7JV+p8j73wnS/0gNl3S2Mpgry6ONyLFjYyZ/ve5AFCztH1XcfrVgPYoSSzuZZuraDrnSetqb4oDvx2hls2ih857IEd9wWY9dZDrf+vot3vNPz79jQWH3rdqgGUA1juGMKYgSyviPFa+s6iUXCI8L9hSr86Y4oV3wzQccW4fNnp/nilzIkktvSDMTWb5W9YVTGFMQII+e4vLqmg5aG4TsQXbxGYcIkZcwYlxdfiLD/2/JcflWKffa14IKGMRSYghhBdKdzZPPusDYpla5pWLdGWLdGOPb4LFf+IBXo5MwwjNowPJuYxnY4rvLauk5CIsNWOUCwO2YQnng0YsrBMIYY60GMENo7UvRk8oO+knKoWLNa+NXNMVaXcfJW7rhhGLXDFMQIIJ3N88b6LloaYmza2cL0kyXPhfj5DXHu+b8orguJJIFunwfb1YRhGH1jJqZhjqryensX0XCIcB12H4LCLrouPHh/hFOOb+TYDzTz13ujnHxalvv/0cnlV/VvTYNhGLXDehDDnA1dGTb3ZBlbh9NZg5zoXXhOku98K8H69hCTp7h87RspTvh4lpZWL8+MXW3FrmHUC6YghjHZvMPy9k6ak/URcL6UICd6uZywZTNc8z89fOBDOaIBotsaBcOoD0xBDGNWbOhGFaJ1ut6h3MByPg8fPtZ6BIZR79RnzWL0SUdPlvaOVN32HgAmTQ4eWLYB59qgeJH+cnkXx9WtEQB3Nq5CTyZPJufgBHlVrHOyeYctPVk2d2VwXGVzV4Z0Njiex0jDehDDEMd1Wbqug6ZEtG6d723eJETCXljIYtfaNuA8+KSyeVJZBxRikRB5R0nn8uQdF9Xejs0LKiMkgojg1lCHuKps6c4iAq0NMTK5PKmcQz6fBxQXTzYRIRwSIiEhHA4R2cmTLVSVdM4hk8uDCg3xCNPGNdKSjPHEygh7TG5hzeYUm7oyRCMhGuKRYb32qBKmIIYhqzb1kM+7NMbrs/ewcYNw2scaWbcuxKc/n+Heu2I24DzIqCo9mTzZvEtrY4xZE1tYtDLMXlPaeqVzXK834bqKU7TlHZec47JOYGNXhpZkdFBds2TzDl2pHNPGNdKzMszMic1bz7m67f55R8nlHVLZPOmcSzqbpyfj4LjKlm4vEJMCEX+WXiQUIhwe/MWgjquksp5SFYHWZJypYxtpTkaJRXqv0BzTlGBMU4LuTI72LSnaO9II0JgY3GdYD5iCGGZ0p3Os3thNa51Gg2tf5ymH5a+HuP7mHt51WJ4LLsnYgPMg4arSnfYqsnEtCXZpS1ZsKIRDISrVWS9Fw+y+SwvL2zsBBqVX2tGTJRwS3jR9DC3JGC+XnA+JEIuEt6t4C6gqC96I8OYZY8k5Lrm8SybnbO0p9aRyvXpGBQVSMGUFiV98qPD9VD1ZXVcJh4VxzQnGNMZpTESqirfeGI/SODHKlLGNbOzKsGZTD13pHMlYhHh0ZCz7NwUxjHBVWdbeSSJWn13atWuET57QyJpVIX72y+6trriNHcd1la50DleVia1JJrUmScQG5+c7vjlBSzLKig3dtHekaUpEylbelXBcpaMny9jmODPGNw3oGuBV4AIkYxGSAedVlXxRL6igQNpDQktDDFBQpTAEUzB0auEDoHgRA6eMbaAlGSO5A2aiWCTMLm0NTGhJ0tGTYXWJ+Wk4U1PpReRI4EdAGLhRVb9Tcv4HwFx/twGYqKptRedbgCXAnap6Zi1lHQ60b0nRnc7XpQvv1SuFT/5nI+vXhbjxN90ceLAph8HAcV26UjkUmDzGq4Rq0TqNRcLsNqmFsU1xlrV3ksrkaW6IVV1peiYih10nNDOxNVHTsTERIRoWouFQLwXyUiTErCJTVl+seinM5DGNgyZXOCS9zE/rtqRY35H2zGV+r2rb1r+FrarbTIN5V3H88aVC1ygUkqAgujtMzRSEiISB64D3ASuAhSIyX1WXFNKo6jlF6c8C3lZymW8Dj9RKxuFEOuew3HenUW+8sVw49YQmtmwRbp7XzQGzR69ycFXJ5X37et7d+gN2XGWzb1MXtg0WlxISIRTybOyO65mTpo5rZHxLckimM7c1xtkvEWXVpm7WbErREK9sLlH1Kr9ELMx+08cO+xbzYNEYjzJrYpSpYxv52/IwMyc0kc45ZHMOmbxLOpcnl/dmdBW/DyERXFU6U1kcV/3XR1CUeDRMMhqhIREhGQsTDYeJRkJEwyH+tiJcE6Vcy9I8CHhFVZcCiMg84Bi8HkEQJwHfLOyIyGxgEnAvMKqN16rK8vbOrQN19cTrr4X45AmN9PTALb/r5i1vHR3KQVW3mjdyzrYfuoSEpniEtsYEjfEosWiIWCTMP1ZEmLP7BFy/JeiqZzZyVbf+d1wl77o4jtdSbI+GeevMcUM+8BkJh5gxvpmxTQleW9fB5u4MLckYoZJ3L+e4dKayTGpNMn18U1V2+9FGLBImHBLGt2xvLHOLewWO4rgu2bzLhtdCTB7TQCIa2aoAopHQTjEr11JBTAXeKNpfARwclFBEdgVmAQ/6+yHgauATwHtrKOOwYFNXhk3d9edO49WXQ5z6sUZyWfjFbd3su9/OneOuqiieWUYGwe2543o/3LzjzwRSr0XnuEpnyhuMHNMUpzEeIR6NEI96P+ZyLTkRISxScdC4mKUh2amzYpoSUfadNpa1W3pYub6bWDS8tYfQnc7huMpek1sZ05TYaTIOZ0IihHxTWTGxSGhQTV87gtRqMY2IHA8cqaqn+/unAAcHjSWIyNeAaap6lr9/JtCgqt8TkdOAOWXynQGcATBp0qTZ8+bNG7C8XV1dNDU11Sz9QPN0dnURjiW8eetVpM+ke4gnGvp1j/7kefCvk7jl5t1Zty5BKASJRJ5rfrCImbO6d6pcjioo5DMpoomG6haJCeTTKaKJJEHJRbatFwiJP3gq0N3VTXNz7cu+nt5JVcjkHVxXyWdSxJINxCPhwBlDQynXjuQZ7XIVmDt37iJVDbTS1LIHsRKYXrQ/zT8WxInAfxXtHwK8W0S+CDQBMRHpUtULijOp6g3ADQBz5szRww47bMDCLliwgP7k72/6gea5/y8PMm7WW6oee+jPdNJtoT2rW6Mw//Yo1167zfme64LjROjK7c9u+1Ve2zCQaa595XH8mT3qKhPbkkxsTfL4P/++9RkXzDeFuf9bzTtbB/tcnlv0OG864ECSsQjRSJiI36KLhMt36Yeq7OvtnXRV2dCZ5pmFj3L44XOr7qGN1udV73JVQy0VxEJgTxGZhacYTgQ+XppIRPYBxgCPFo6p6slF50/D60FcUJp3pLN2c4qc49bEnUaQp9WLz/fspB/5aI5NG4Xly0Isfz209f/d/xcll+1dKWQywjVXJoZ08VvOcelO5xARpoxpYHxLInBKZaELX2m25YuRENPHVz/zZTQTEmFCS7Ki8jRGFjVTEKqa901F9+FNc/25qi4WkcuAJ1V1vp/0RGCe1ovjmDrAVWXlhm5WbeomHJKazE4I8rSaTgkXnJPk0guTdHX2PjdpsksuG3ytoYr2ls07dKdzxKJhdp3QzNim+IhbuWoY9URN56Sp6j3APSXHLinZv7SPa9wC3DLIotUtecfltbUdbOrOMqYxzuYa3aesp9UcHPuJLDNmuszY1WXGTJdp010SSTjswGZWrdw+X62d76WyedLZPMl4hD12aaW1MV53s7kMYyRik5briHTO4ZXVW8jknJothluzWrj+2njgoCzAlKnKJVcEO9M798J0L7MU1Nb5nqveDK6WhigzJ4yhOVm/zgkNYyRiCqJO6E7neHHVZsKhUE0Ww61vF274SZzf3BpDXTjk3XmeWhghk66+si+MMwxFtLeOHs8L6JtnjKlbp4SGMdIxBVEHbOxM88raDhpq4ORr00bhputj/PKmONksHHt8ji+ek2b6DO33LCYYmmhvnaksyViYeDRsysEwdiKmIHYiqsrqzT280e650NiRAddtlf3hTJ6ifPHLadasDnHzDXF6ur0Ibmeem2HW7tsWs9VjaM/OVJZENMyeU9pY9+rOlsYwRjdVKQgRaQC+AsxQ1c+KyJ7A3qr6p5pKN4JxXM99RntHmrbG+HZuDPpD+Smrwgc+lOPs89LsuXf9R/LqTOWI+8qhXsOoGsZootoexM3AIrwFbOCta/g9YApiAGTzDq+u7aArlaOtMbbDA69BU1ZBmDDR5cc/69mhaw8VnakcsUiIPSe3mnIwjDqh2l/i7qr6PSAHoKo9UBPvsiOeVDbPCys2kco4tDXGB2VWTrkpq+vbh0cRdaU95bDXlNYBxxAwDGPwqVZBZEUkie+VVkR2BzI1k2qE4rjK88s3IiKDujq63DqEWq9PGAy60jkiYTHlYBh1SLUK4pt4breni8ivgb8CX62ZVCOQjlSWTM6hMR4lOUiRwAocMDu/3bFark8YLArKYe8pbaYcDKMOqaqmUtUHROQp4B14pqUvqer6mko2gkhl87y0ajOhkBCNDK59/cnHw9x3d5S3vj1P+9pQzdcnDBbd6RyRkCkHw6hnqp3F9FHgQVW9299vE5FjVfXOWgo3EsjmHV5atZlYJDzogzYbNwjnfLGBaTNcbv5tN03NA/OaOtR0p3OEQ8LeU005GEY9U7WJSVW3FHZUdTNF0d+MYBzX5ZXVW3CVQTcruS6cf3aSTRuFH13fQ9MwcUjak8kTCgl7Wc/BMOqeahVEUDpbZFcBV5XX1nXSk8nTlBj81cA/uy7O3x6KctG30uz7lvpf4wCechCBvae0DfqKccMwBp9qFcSTInKNiOzub9fgrYswyrByQzcbOzO0Ng6+072Fj4f54ffifPDoLCeeUsYHd53hKoCacjCMYUS1CuIsIAv8zt8y9I4AZxSxdnOKVZu6aWscfKd7GzcI536xgem7ulx+VaqqkI87m3Q2Dyh7Tx1jysEwhhHVzmLqBkZdRLeBsKkrzevtnbQ2DM4iuGJcF84/yxt3+N+7uofFuEM275DOOcSjERKmHAxjWFHtLKa9gPOAmcV5VPXw2og1POlO53hlTQdNyWhNAtrccF2cvy2Ictl3U+y7X/2PO+Qdl+50njdNG8OiFTtbGsMw+ku1A82/B64HbgSc2okzfEnnHF5avZlkLFITX0ILHw/zw+/G+dAxWT72ifofd3BcpSOVZa/JrTWJqW0YRu2pVkHkVfWnNZVkGJNzXF5evZmQhGpiY9+4QTjnCw3MmOny7e/V/7iDq8qW7gwzJ7Ywpimxs8UxDGOAVNvUvUtEvigik0VkbGGrqWTDBMdVXlvbQTbn0hAf/Jm/hXGHzZuEHw6D9Q6qypbuLNPGNTKpLbmzxTEMYweotkY71f9/ftExBXYbXHGGF6rKG+s72dKTpW2Qp7MWAgCtWnk4IPzHx7LDYtxhc3eWia0Jpoxt3NmiGIaxg1Q7i2lWrQUZjqze3MO6LelBn85aGgAI4O75UQ55d76u/Stt6c4wtjnOjAnNgz6DyzCMoadqm4iI7AfsC2w1KqvqrbUQajjguMob67toq8F01qAAQOmUcM2VibpVEJ2pLI3JKLMmNhMy5WAYI4Jqp7l+EzgMT0HcAxwF/B0YtQoi77g0xqM7FCo0iJ4eL2RoEOUCA+1sutM5opEQe+zSSjhk0eAMY6RQ7a/5eOAIYI2qfgp4K9BaM6nqHFXFcbUmrruPfm9T2fP1GAAolc2DwF6TLY60YYw0qv1Fp1TVBfIi0gKsA6b3lUlEjhSRF0XkFRHZbiW2iPxARJ72t5dEZLN//AAReVREFovIsyLysX58p5qTyXuDxYNlSkmn4MpvJTj5uEZcV/jilzMkkr2VQT0GAMrmHXJ51/wrGcYIpdoxiCdFpA34GZ6Tvi7g0UoZRCQMXAe8D1gBLBSR+aq6pJBGVc8pSn8W8DZ/twf4pKq+LCJTgEUicp/vZnyn4/kWGhyeeSrMV7+U5LVXw3z81AznX5ymsRF228PlmisTdRsASIHuTJ59p40ZdFfmhmHUB9XOYvqi//F6EbkXaFHVZ/vIdhDwiqouBRCRecAxwJIy6U/CjzGhqi8V3XuViKwDJgCbq5G31vRkPLPKjpDNwLVXx7nxf+JM2kW5eV4X73zPtkXqRx+X4+jjcnUXAMh1lUzewXGVPXdpqYkrc8Mw6gNRrc6uLSL7s70vptsrpD8eOFJVT/f3TwEOVtUzA9LuCjwGTFNVp+TcQcAvgDf7Zq7ic2cAZwBMmjRp9rx586r6LkF0dXXR1FTe/l9MOueQTfUQTzZUlf7Bv07ilpt3p709wYQJaY48aiWPPLwLy5Y18f4PrOJzn3+JxsZgDyaZdA/xRHX3GUj6avK46o27ACAQDgnZVA/NzdWv2uvP8x3KPPUq10DymFwm10CYO3fuIlUNbIVWO4vp58D+wGKgUEkrUFZB9JMTgT8EKIfJwC+BU0uVA4Cq3gDcADBnzhw97LDDBizAggULqCa/q8q/lq5n/dJnq2rZz789yrXXblvTsG5dklt/sTvNLcr/3trN3Pc2ss2ytj397UEMpMdRnEdVyeZd0jkHV5WwCM3JKGOa4jTGoyRiYUIiVT+vAv1NP1R56lWugeQxuUyuwaZa4/E7VHXffl57Jb0Hsqf5x4I4kZL4Ev5g+N3ARar6WD/vXTOyfsVZLUFrGkBobFTmvnfwxjJ2BAU6erK4qohAUzzK9HGNNCWiJGKRmnimNQyj/qlWQTwqIvsWDzBXwUJgTxGZhacYTgQ+XppIRPYBxlA06C0iMeAO4FZV/UM/7llz0rn+ObMtt3Zh7ZqdV+kWegmpbB5VQGHK2AaaEjEa4mFby2AYBlC9grgVT0mswYsmJ4Cq6v7lMqhqXkTOBO4DwsDPVXWxiFwGPKmq8/2kJwLztPdgyH8C7wHGichp/rHTVPXpKuWtGV3pHJF+zPefPEUDF74N9ZoGV5VMziGddRCgpSHKLhObaU7GeHRlmMljzHeSYRi9qVZB3AScAjzHtjGIPlHVe/BWXhcfu6Rk/9KAfL8CflXtfYaSjp4csX4skDv7vDQXnJOkeNrTUK1pcF0llc2Tc1xEoK0hzvRxjTQmosQitm7BMIzKVKsg2ota/KMWx1V6MnlaGqqf2tnZKYAwbrzLxg21X9OgQGcqh+O4hELC2OY4Y5sSNCUiZjoyDKNfVKsg/iUivwHuwjMxAZWnuY5EMjkHRat2ztfdDT/9UZx3vCvPrbd113xNg+O6OK4yoSVBW2OchrgNMBuGMXCqVRBJPMXw/qJjgznNdViQ6ecA9a03xtm4IcS5X+upkUTbcF0vUE88Gmb6+IHNhzYMwyimTwXhu8zYoKrnDYE8dU1nKlv1APWWzXDjT+Mc8f4cB8yubRhvV5XNPRl2ndjMv+vU46thGMOPPms7f/HaO4dAlrqnI5UjXuXg7o0/jdPVCV/6am0Ho1WVzV0Zpo5tZJe2/q2gNgzDqES1JqanRWQ+8Hugu3BwNI1BOK63bqCa0KLt64Rbb4zzoWNy7LNvbcOEbu7OMqktyVQL8WkYxiBTrYJIABuAw4uOjaoxiP4skLv+2jjZLJx9XqbvxDuAhfg0DKOWVOvN9VO1FqTeSWWqc4uxcoUw71cxjvtYjpm71a730NGTpTkZsxCfhmHUjKpGXEVkmojcISLr/O2PIjKt1sLVE13pfFWLy667xgvZfeY5tRt76ErnSMTC7L5Li61tMAyjZlRbu9wMzAem+Ntd/rFRQ2cq22eI0aWvhLj9tignn5pl8tTauNLoyeQJh4Q9J7f2y+WHYRhGf6m2hpmgqjerat7fbsEL4DMqyDue++u+Yi7/6Ko4iQR87qzajD2ks3lcddlrSpu5yjAMo+ZUqyA2iMgnRCTsb5/AG7QeFVSzQG7J8yH+fFeMUz+bYdz4we89ZPMOmbzD3lPGkLD4z4ZhDAHVKohP43lYXQOsBo4HRs3AdaqKGNQ//F6CllblM58f/N5DznHpzuTZe8oYGuIW/9kwjKGhYm0jIt9V1a8BB6nq0UMkU93Rmc5VNOkseiLMgr9E+cqFaVpaB/fenvO9LHtPaaM5afGfDcMYOvrqQXxQvAn2Fw6FMPXKlp4s8Wjwo1KFH3w3wfgJLqd8ZnB7DwXne7vv0lrVAj3DMIzBpC97xb3AJqBJRDrwAwWxLWBQS43l2+nkHJdc3qUxHtx6/+cjEZ54NMLF307RMEieLhzXpTOVIyRCPBJmfHNicC5sGIbRDyr2IFT1fFVtA+5W1RZVbS7+PzQi7lzS2fID1Kpw9XfiTJnqcuInsjt8L8d12dKdoTudZ/r4Jt46cxyRsC2CMwxj51CtN9dRoQyCSGXzZd1YPHBvhOefifDfV/cQ2wELkOMqnaksIRGmjW9kfHPS1jgYhrHT6VNBqKojIq6ItKrqlqEQqp7oSGUDQ4w6Dvzoewlm7eZw7AkDiw7nuEpXKouIMG1cI+Nbkn2utTAMwxgqqp0z2QU8JyIP0Nub69k1kaqO6ErlSMS2Pab5t0e55soEq1YeDgif+FSGSD9nnhYrhqmmGAzDqFOqrdpuZxR5bi2QzTveAHXCMzHNvz3KxecnSae2mZz+MC/GAbOdqmJMK54HVgSmjGtkgikGwzDqmGq9uf5CRJLADFV9scYy1Q3pnOPN1/K55spEL+UAkE4J11yZ6FNBuKo4rjJlbCPjWxLmKsMwjLqnWm+uHwGexpv2iogc4AcQGtH0ZPK9XGmvLhPOs9zx0mtFwyGmjG005WAYxrCgWvvGpcBBwGYAVX0a2K0mEtURnT25XgPUk6cE+1gqd7yYXN6xKauGYQwrqlUQuYAZTH1GwxGRI0XkRRF5RUQuCDj/AxF52t9eEpHNRedOFZGX/e3UKuUcNFSVznS2V2v/3AvTxBO9lUEiqZx7YeXYD3nHJRYNW2AfwzCGFdUOUi8WkY8DYRHZEzgb+GelDP76ieuA9wErgIUiMl9VlxTSqOo5RenPAt7mfx4LfBOYgze2u8jPu6nqb7aDZPMurguh0LZK/ejjcix6Isxvb40DypSpnnLoa/yhO5Nn6tgGr/tlGIYxTKi2B3EW8GYgA/wG2AJ8uY88BwGvqOpSVc0C84BjKqQ/Cfit//kDwAOqutFXCg8AR1Yp66Dgufje3nTkOEJzi3L3nx9kwcLOqmYvua7LGPOlZBjGMENUy9vPRSQBfB7YA3gOuElVqwrOLCLHA0eq6un+/inAwap6ZkDaXYHHgGn+wrzzgISqXu6f/waQUtXvl+Q7AzgDYNKkSbPnzZtXjWiBdHV10dTUtHU/57jkHJdwiVnoM59+B9Om9vD1ix4jnujb+ZL6nqsS0fB29xiIXIOdfqjymFyj97uYXPUpV4G5c+cuUtU5gSdVtewG/A74FfA54E7gh5XSl+Q9HrixaP8U4Cdl0n4N+HHR/nnAxUX73wDOq3S/2bNn647w0EMP9dr/98pN+tzrG/SlVZu3bv94eouC6lcv7tF77/9Lr3PltsdfWqvrO1KB9xiIXIOdfqjymFy1z2Ny9S/PaJerAPCklqlX+xqD2FdV3wIgIjcBT/RDMa0EphftT/OPBXEi8F8leQ8rybugH/feIVSVrlSOppL4Cwsf8x7XgYf0HWEOvLUPoRC0NsQGXUbDMIxa09cYxFYDu1ZpWipiIbCniMwSkRieEthu7YSI7AOMAR4tOnwf8H4RGSMiY4D3+8eGhEze9Sr3EvPSE4+GaWhQ9t2vOgWRyuQZ15Qwx3uGYQxL+upBvNWPAwHemuJkcVwIreDyW1XzInImXsUeBn6uqotF5DK8Lk1BWZwIzPO7OoW8G0Xk23hKBuAyVd3Y7283QNJlQow++XiEtx+YJ1plYLdc3mVci8VyMAxjeFJRQajqDi35VdV7gHtKjl1Ssn9pmbw/B36+I/cfKD2ZPOFQ71b/xg3CS/8O86Fjq/PcmndcopEQTQkLE2oYxvDEbB8BbOnZ3sX3oic8XXngwdVZ2noyeSa1JW1xnGEYwxZTECW4qvRk8tspiIWPRYgnlP0PqG78wbG1D4ZhDHNMQZSQzTm4rm4XRW7hYxEOeLtTVeS4TM6hKRnrFUfCMAxjuGEKooRSF98AnR3wwuIQB76jH+al1mQNpDMMwxg6TEGU0JXObTct9cknIriuVKUgXFVEoMXWPhiGMcwxBVFCR4mLb4AnH4sQjSoHvL3v8YdUJs+45oRFijMMY9hjtVgRjqtbA/sU88RjYd5ygEOyb9dLZPMu423tg2EYIwBTEEVkcg5K7wHq7m5Y/Gy4KvOS47pEw7b2wTCMkYEpiCI8F9+9efrJCPm8cFAV/pe607b2wTCMkYMpiCI6U9ntzEsLHw8TDitvm1NND0IZ02RrHwzDGBmYgiiiI5XrFWIU4IlHI+z7Foe+XK1ncg6N8QhJW/tgGMYIwRREEalsnmjRDKZ0Cp75V5iD3lHF7KWsZ14yDMMYKZiC8HEDIus9+3SYXLbv9Q+FvK3mWsMwjBGEKQgfNyDy6hOPRhBRZh9UWUGksw5jbe2DYRgjDKvRfFxXtxt/WPhYhL3f5NLaVjlvNu8wwdY+GIYxwjAF4eO42mv8IZuFfz0Z5qBDKvceHNclErK1D4ZhjDxMQeAF91HVXiai558Jk04LB/ahIGztg2EYIxVTEAQvkFv4mDdd9cCDK89gsrUPhmGMVExBUGaA+rEwe+zlMHZcwEkfW/tgGMZIxhREAPk8PLUw0uf01lQ2Z2sfDMMYsZiCCOCFxWG6u4QD+1wgJ7b2wTCMEYspiAAWPuZNd63Ug3AVxjbFbe2DYRgjFqvdAlj4aIRdZzlM2qX8+IOqMqHFzEuGYYxcTEGU4Lrw5BPhiualgmuNxoQNThuGMXKpqYIQkSNF5EUReUVELiiT5j9FZImILBaR3xQd/55/7AURuVZkaBYavPTvEFs2hyqalzI5h3BICIdMvxqGMXKpWRNYRMLAdcD7gBXAQhGZr6pLitLsCVwIvFNVN4nIRP/4/wPeCezvJ/07cCiwoFbyFnjiUe+RVFpBnck5RGzswTCMEU4ta7mDgFdUdamqZoF5wDElaT4LXKeqmwBUdZ1/XIEEEAPiQBRYW0NZt/Lk4xGmTHWZOq3C+AMQCtnKacMwRjaiAW6uB+XCIscDR6rq6f7+KcDBqnpmUZo7gZfwegth4FJVvdc/933gdECAn6jqRQH3OAM4A2DSpEmz582bNyBZXVW6OruIJRo46WPvZvacDZz/1SWBadX/k8+maOorilAJXV1dNc8zFPcwueozj8llcg2EuXPnLlLVOYEnVbUmG3A8cGPR/il4FX1xmj8Bd+D1EGYBbwBtwB7A3UCTvz0KvLvS/WbPnq0DpaMnq3ff+4D++eEOBdUrvt+tL63aHLg98fJaXbOpWx966KF+32co8phc/ctTr3INJI/J1b88o12uAsCTWqZeraWJaSUwvWh/mn+smBXAfFXNqepreL2JPYGPAo+papeqdgF/Bg6poaxAkf+lSgvkFJqTsVqLYhiGsdOppYJYCOwpIrNEJAacCMwvSXMncBiAiIwH9gKWAsuBQ0UkIiJRvAHqF2ooKwBPPBpm4iSXXWe5gefzjks0GiIZCweeNwzDGEnUTEGoah44E7gPr3K/TVUXi8hlInK0n+w+YIOILAEeAs5X1Q3AH4BXgeeAZ4BnVPWuWsnqyQsLH48w5+A85SbUprIO45oTDNGMW8MwjJ1KTVd6qeo9wD0lxy4p+qzAuf5WnMYBPldL2UpZszrJ2tUhDjqkvHnJcV3aGsz3kmEYowObzO/z/PNtQHn/S64qIREa4rZ62jCM0YEpCJ/nnh3DmLEue+wVPP6Qzjq0NcYI2/oHwzBGCaYgfJ5/bgwHvsMpO/6QzXvjD4ZhGKMFUxDAG2/A2rXJsuYlVQXFzEuGYYwqTEEA//i7120opyCyeZemZJRYxKa3GoYxehj1CuLXv4Zzzg4Dyhc/1cj826PbpUln82ZeMgxj1DGqbSa//jWccQb09Hg9iFUrhYvP94IAHX1cbms6F2hJbq84DMMwRjKjugdx0UXQ09P7WDolXHPltt5CznGJR8LEo2ZeMgxjdDGqFcTy5cHHV6/aNpUpnc0zvjluq6cNwxh1jGoFMWNG8PHJU7a5QM87Lq2NtnraMIzRx6hWEFdcAQ0NvY8lksq5F6YBcF0lHArZ9FbDMEYlo1pBnHwy3HADTJ+uiChTprpcflVq6wB1OucwtjlOyMxLhmGMQkZ90/jkk+Ho4/L87ZGH2XP/A3udy+YcxjQOLEqTYRjGcGdU9yAqoaog0Jiw6a2GYYxOTEGUIZt3aWmIEg3bIzIMY3RitV8ZUtk8Y5ts9bRhGKMXUxDlsNjThmGMckxBBJDLuyRiYRK2etowjFGMKYgAUtk841rMvGQYxujGFEQArqu0mnnJMIxRjimIEhxXCYeFpK2eNgxjlGMKooRC7AdbPW0YxmjHFEQJOcelzZzzGYZhmIIoRtXz4tpo5iXDMIzaKggROVJEXhSRV0TkgjJp/lNElojIYhH5TdHxGSJyv4i84J+fWUtZwXPO19oQI2Krpw3DMGrnrE9EwsB1wPuAFcBCEZmvqkuK0uwJXAi8U1U3icjEokvcClyhqg+ISBNe5M+aksk5TBnT0HdCwzCMUUAtm8oHAa+o6lJVzQLzgGNK0nwWuE5VNwGo6joAEdkXiKjqA/7xLlUtCQ5aA2z1tGEYxlakYHcf9AuLHA8cqaqn+/unAAer6plFae4EXgLeCYSBS1X1XhE5FjgdyAKzgL8AF6iqU3KPM4AzACZNmjR73rx5A5LVVaWzs4tYooFkrLrV011dXTQ19c8V+FDkMblGhlwDyWNymVwDYe7cuYtUdU7gSVWtyQYcD9xYtH8K8JOSNH8C7gCieIrgDaDNz7sF2A3PDPZH4DOV7jd79mwdKB09Wb3rz/fr6k3dVed56KGH+n2fochjcvUvT73KNZA8Jlf/8ox2uQoAT2qZerWWJqaVwPSi/Wn+sWJWAPNVNaeqr+H1Jvb0jz+tnnkqD9wJvL2GsiIiNCct9oNhGEaBWiqIhcCeIjJLRGLAicD8kjR3AocBiMh4YC9gqZ+3TUQm+OkOB5ZQQ8IiNMRseqthGEaBmikIv+V/JnAf8AJwm6ouFpHLRORoP9l9wAYRWQI8BJyvqhvUG2s4D/iriDwHCPCzWskaCQuRsCC2etowDGMrNW0yq+o9wD0lxy4p+qzAuf5WmvcBYP9aylcgGYvY2gfDMIwSrFY0DMMwAjEFYRiGYQRiCsIwDMMIxBSEYRiGEYgpCMMwDCMQUxCGYRhGIKYgDMMwjEBMQRiGYRiB1Myb61AjIu3A6ztwifHA+hqmH6o8JtfIkGsgeUwuk2sg7KqqEwLPlPPiN9o2Kng0HIz0Q5XH5BoZco2k72Jy1adc1WxmYjIMwzACMQVhGIZhBGIKYhs31Dj9UOUxuervHkOVx+Sqv3sMJM9QydUnI2aQ2jAMwxhcrAdhGIZhBGIKwjAMwwhk1CsIEfm5iKwTkeerTD9dRB4SkSUislhEvlRFnoSIPCEiz/h5vlXlvcIi8i8R+VOV6ZeJyHMi8rSIPFllnjYR+YOI/FtEXhCRQyqk3du/dmHrEJEvV3GPc/zv/byI/FZEElXk+ZKffnG5ewSVnYiMFZEHRORl//+YPtKf4N/DFZE5Vd7jKv95PSsid4hIWxV5vu2nf1pE7heRKZXSF537ioioH5K3r3tcKiIri8rng33l8Y+f5X+fxSLyvT7u8bui6y8TkaerkOsAEXms8F6KyEFV5HmriDzqv893iUhL0bnA32AfZV8uT2D5V0hftuwr5KlU9hXrk9Lyr3CPimU/YGoxd3Y4bcB7gLcDz1eZfjLwdv9zM/ASsG8feQRo8j9HgceBd1Rxr3OB3wB/qlK2ZcD4fn7/XwCn+59jQFuV+cLAGrxFNpXSTQVeA5L+/m3AaX3k2Q94HmjAi3r4F2CPasoO+B5wgf/5AuC7faR/E7A3sACYU+U93g9E/M/fLb5HhTwtRZ/PBq7v6x0EpuOF5X29tFzL3ONS4Lz+vOvAXP/5xv39idX+NoCrgUuquMf9wFH+5w8CC6rIsxA41P/8aeDbRecCf4N9lH25PIHlXyF92bKvkKdS2ZetT4LKv8I9Kpb9QLdR34NQ1UeAjf1Iv1pVn/I/d+LF257aRx5V1S5/N+pvFWcHiMg04EPAjdXK1l9EpBXvx3mTL2dWVTdXmf0I4FVVrWb1egRIikgEr9Jf1Uf6NwGPq2qPerHNHwaOK01UpuyOwVN6+P+PrZReVV9Q1RfLCVImz/2+XACPAdOqyNNRtNtIUflXeAd/AHyVgHelv+9thTxfAL6jqhk/zbpq7iEiAvwn8Nsq7qFAoQfQSkn5l8mzF/CI//kB4D+K0pf7DVYq+8A85cq/QvqyZV8hT6Wyr1SfbFf+A6l/doRRryB2BBGZCbwNr0fQV9qw3x1fBzygqn3l+SHey+H2QyQF7heRRSJyRhXpZwHtwM3imbJuFJHGKu91IiWVQ6BAqiuB7wPLgdXAFlW9v49szwPvFpFxItKA1+qcXqVck1R1tf95DTCpynwD5dPAn6tJKCJXiMgbwMnAJX2kPQZYqarP9FOeM31zxs+LTSwV2AvvWT8uIg+LyIFV3ufdwFpVfbmKtF8GrvK/+/eBC6vIsxivwgc4gTLlX/IbrKrs+/O77SN92bIvzVNN2Rfnqab8A+Tqb9n3iSmIASIiTcAfgS+XtBACUVVHVQ/Aa3EcJCL7Vbj2h4F1qrqon2K9S1XfDhwF/JeIvKeP9BG8rv1PVfVtQDde17wiIhIDjgZ+X0XaMXg/9FnAFKBRRD5RKY+qvoDXfb8fuBd4GnD6ulfAdZQ+emo7gohcBOSBX1cpz0WqOt1Pf2aF6zYAX6cPJRLAT4HdgQPwlPHVVeSJAGOBdwDnA7f5vYO+OIkqGgg+XwDO8b/7Ofg91j74NPBFEVmEZ0rJliao9BssV/b9/d2WS1+p7IPy9FX2xXn861Ys/4B7DKTs+8QUxAAQkShe4fxaVW/vT17fhPMQcGSFZO8EjhaRZcA84HAR+VUV117p/18H3AEcVDkHK4AVRb2ZP+ApjL44CnhKVddWkfa9wGuq2q6qOeB24P/1lUlVb1LV2ar6HmATnq21GtaKyGQA//+6PtIPCBE5DfgwcLJfGfWHX1NkMglgdzyF+oz/DkwDnhKRXSpdVFXX+g0RF/gZfZc/eO/A7b4Z9Am8Huv4Shl8U+FxwO+quD7AqXjlDl6jok+5VPXfqvp+VZ2Np4heLZEh6DdYsez7+7stl75S2Vdxj+3KPiBPxfIPuscAy75PTEH0E791dRPwgqpeU2WeCYXZDiKSBN4H/LtcelW9UFWnqepMPFPOg6pasdUtIo0i0lz4jDeYVnFmlqquAd4Qkb39Q0cAS6r4Sv1pPS4H3iEiDf6zOwLPbloREZno/5+BVxn9psr7zcerkPD//1+V+apGRI7EM/8drao9VebZs2j3GCqX/3OqOlFVZ/rvwAq8gck1fdxjctHuR+mj/H3uxBuoRkT2wpuo0JdX0PcC/1bVFVVcH7wxh0P9z4cDfZqliso/BFwMXF90rtxvsGzZ9/d3Wy59pbKvkKds2QflqVT+Fe4xkLLvGx3kUe/htuFVdKuBnF8Qn+kj/bvwuq7P4pk+ngY+2Eee/YF/+Xmep2TmRx95D6OKWUzAbsAz/rYYuKjK6x8APOnLdicwpo/0jcAGoLUf3+FbeD+K54Ff4s+Y6SPP3/CU1TPAEdWWHTAO+CteJfQXYGwf6T/qf84Aa4H7qrjHK8AbReV/fRV5/uh//2eBu/AGL6t6BwmYnVbmHr8EnvPvMR+YXEWeGPArX7angMP7kgu4Bfh8P8rkXcAivywfB2ZXkedLeL3Gl4Dv4Ht9qPQb7KPsy+UJLP8K6cuWfYU8lcq+z/qkuPwr3KNi2Q90M1cbhmEYRiBmYjIMwzACMQVhGIZhBGIKwjAMwwjEFIRhGIYRiCkIwzAMIxBTEEbd43uzvLpo/zwRuXSQrn2LiBw/GNfq4z4niOct96GS4zNFJCW9veTGBnD906TIS6hhDAamIIzhQAY4TkpcXu9s/BXF1fIZ4LOqOjfg3KuqekDRtp1biSo4Dc+VSdX0U35jFGIKwhgO5PFi7p5TeqK0ByAiXf7/w3znc/8nIktF5DsicrJ4cTmeE5Hdiy7zXvHiFLzk+8EqOFe8SkQW+g7QPld03b+JyHwCVp2LyEn+9Z8Xke/6xy7BW+B0k4hcVc0XFpH3ixcP4SkR+b3vewcRucSX6XkRuUE8jgfmAL/2eyBJ8WI1FGIIzBGRBf7nS0XklyLyD+CX/ir/P/rXXCgi7/TTHVrUo/lXYZW+McoYjNV2ttlWyw3ownMXvQzPXfR5wKX+uVuA44vT+v8PAzbj+c+PAyuBb/nnvgT8sCj/vXiNpT3xVtUmgDOAi/00cbzV5rP863YDswLknILnWmQCnhO8B4Fj/XMLCI43MRNIsW1V7HV4vpAeARr9NF/DX31P79XBvwQ+EnR9eq++nYMfgwEvbsAitsXn+A2ek0eAGXguHMBb8ftO/3MTfgwE20bXZl1MY1igqh0icitewJVUldkWqu/+WURexfMOC55LgmJTz23qOTl7WUSWAvvg+bLav6h30oqnQLLAE6r6WsD9DsSriNv9e/4aL97GnX3I+ap6nn7x830YLwjMPzzXO8SAR/3Tc0Xkq3hxNcbiuVW5q4/rlzJfVQvP8L3AvrLNgWuL31v5B3CN/x1u1+r9LhkjCFMQxnDih3j+gm4uOpbHN5X6jt2KB3gzRZ/don2X3u9+qb8ZxYsCeJaq3ld8QkQOw+tB1BLBixlyUsm9E8D/4PUU3vAH6suFb936XALSFMsfwotumC5J8x0RuRvPz88/ROQDqlrWwaAxMrExCGPYoKob8UKWfqbo8DJgtv/5aLxoff3lBBEJ+eMSuwEv4oV6/IJ4rpURkb2k72BKTwCHish4EQnjeb19eADyPAa8U0T28O/dKJ6n1UJFv95v5RfPvurEi5tQYBnbnksl1+L3A2cVdkTkAP//7up5Ff0uXvjPfQbwPYxhjikIY7hxNb3jFfwMr1J+BjiEgbXul+NV7n/G81Kaxgv1ugTPD//zwP/SR4/bN2ddgBfv4xlgkar22924b6I6DfitiDyLZ17aR71YIj/D8wx6H17FXeAW4PrCIDWeB90ficiTVA62dDYwxx+IXwJ83j/+ZX8g/Fk8L6tVRc0zRhbmzdUwDMMIxHoQhmEYRiCmIAzDMIxATEEYhmEYgZiCMAzDMAIxBWEYhmEEYgrCMAzDCMQUhGEYhhHI/weYfhBUfJmCWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print chart\n",
    "fig = plot_sfs(sfs.get_metric_dict(), kind=\"std_err\")\n",
    "plt.title(\"Sequential Forward Selection (w. StdErr)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(7,)</td>\n",
       "      <td>[0.7095238095238096, 0.7142857142857143, 0.647...</td>\n",
       "      <td>0.34381</td>\n",
       "      <td>(chk_acct_A14,)</td>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.042255</td>\n",
       "      <td>0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(7, 35)</td>\n",
       "      <td>[0.7547619047619046, 0.7121428571428572, 0.658...</td>\n",
       "      <td>0.406381</td>\n",
       "      <td>(chk_acct_A14, property_A121)</td>\n",
       "      <td>0.044722</td>\n",
       "      <td>0.060214</td>\n",
       "      <td>0.020071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(7, 22, 35)</td>\n",
       "      <td>[0.7607142857142858, 0.7559523809523809, 0.688...</td>\n",
       "      <td>0.435667</td>\n",
       "      <td>(chk_acct_A14, saving_acct_A65, property_A121)</td>\n",
       "      <td>0.031763</td>\n",
       "      <td>0.042767</td>\n",
       "      <td>0.014256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(6, 7, 22, 35)</td>\n",
       "      <td>[0.7711904761904762, 0.771904761904762, 0.6902...</td>\n",
       "      <td>0.446</td>\n",
       "      <td>(chk_acct_A13, chk_acct_A14, saving_acct_A65, ...</td>\n",
       "      <td>0.034671</td>\n",
       "      <td>0.046682</td>\n",
       "      <td>0.015561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(6, 7, 22, 35, 41)</td>\n",
       "      <td>[0.793809523809524, 0.7566666666666667, 0.7026...</td>\n",
       "      <td>0.466381</td>\n",
       "      <td>(chk_acct_A13, chk_acct_A14, saving_acct_A65, ...</td>\n",
       "      <td>0.038801</td>\n",
       "      <td>0.052242</td>\n",
       "      <td>0.017414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(6, 7, 22, 30, 35, 41)</td>\n",
       "      <td>[0.7904761904761906, 0.7823809523809524, 0.742...</td>\n",
       "      <td>0.474238</td>\n",
       "      <td>(chk_acct_A13, chk_acct_A14, saving_acct_A65, ...</td>\n",
       "      <td>0.042182</td>\n",
       "      <td>0.056794</td>\n",
       "      <td>0.018931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(6, 7, 22, 30, 35, 38, 41)</td>\n",
       "      <td>[0.7816666666666666, 0.7635714285714285, 0.717...</td>\n",
       "      <td>0.476333</td>\n",
       "      <td>(chk_acct_A13, chk_acct_A14, saving_acct_A65, ...</td>\n",
       "      <td>0.040088</td>\n",
       "      <td>0.053975</td>\n",
       "      <td>0.017992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, 6, 7, 22, 30, 35, 38, 41)</td>\n",
       "      <td>[0.7692857142857142, 0.7419047619047618, 0.715...</td>\n",
       "      <td>0.491238</td>\n",
       "      <td>(age, chk_acct_A13, chk_acct_A14, saving_acct_...</td>\n",
       "      <td>0.037816</td>\n",
       "      <td>0.050916</td>\n",
       "      <td>0.016972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1, 6, 7, 18, 22, 30, 35, 38, 41)</td>\n",
       "      <td>[0.7752380952380952, 0.7616666666666666, 0.708...</td>\n",
       "      <td>0.498048</td>\n",
       "      <td>(age, chk_acct_A13, chk_acct_A14, saving_acct_...</td>\n",
       "      <td>0.028149</td>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.012633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(1, 6, 7, 8, 18, 22, 30, 35, 38, 41)</td>\n",
       "      <td>[0.779047619047619, 0.7773809523809524, 0.7173...</td>\n",
       "      <td>0.507762</td>\n",
       "      <td>(age, chk_acct_A13, chk_acct_A14, purpose_A40,...</td>\n",
       "      <td>0.031155</td>\n",
       "      <td>0.041947</td>\n",
       "      <td>0.013982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(0, 1, 6, 7, 8, 18, 22, 30, 35, 38, 41)</td>\n",
       "      <td>[0.7538095238095236, 0.799047619047619, 0.7266...</td>\n",
       "      <td>0.507571</td>\n",
       "      <td>(present_resid, age, chk_acct_A13, chk_acct_A1...</td>\n",
       "      <td>0.03212</td>\n",
       "      <td>0.043247</td>\n",
       "      <td>0.014416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(0, 1, 6, 7, 8, 18, 22, 30, 35, 38, 41, 42)</td>\n",
       "      <td>[0.7547619047619047, 0.777142857142857, 0.7273...</td>\n",
       "      <td>0.509</td>\n",
       "      <td>(present_resid, age, chk_acct_A13, chk_acct_A1...</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>0.042616</td>\n",
       "      <td>0.014205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(0, 1, 6, 7, 8, 18, 21, 22, 30, 35, 38, 41, 42)</td>\n",
       "      <td>[0.7576190476190476, 0.7783333333333333, 0.740...</td>\n",
       "      <td>0.512095</td>\n",
       "      <td>(present_resid, age, chk_acct_A13, chk_acct_A1...</td>\n",
       "      <td>0.03214</td>\n",
       "      <td>0.043274</td>\n",
       "      <td>0.014425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(0, 1, 6, 7, 8, 18, 19, 21, 22, 30, 35, 38, 41...</td>\n",
       "      <td>[0.7552380952380953, 0.7745238095238094, 0.734...</td>\n",
       "      <td>0.510429</td>\n",
       "      <td>(present_resid, age, chk_acct_A13, chk_acct_A1...</td>\n",
       "      <td>0.031274</td>\n",
       "      <td>0.042108</td>\n",
       "      <td>0.014036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(0, 1, 6, 7, 8, 9, 18, 19, 21, 22, 30, 35, 38,...</td>\n",
       "      <td>[0.772857142857143, 0.7747619047619048, 0.7321...</td>\n",
       "      <td>0.516905</td>\n",
       "      <td>(present_resid, age, chk_acct_A13, chk_acct_A1...</td>\n",
       "      <td>0.030446</td>\n",
       "      <td>0.040993</td>\n",
       "      <td>0.013664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(0, 1, 6, 7, 8, 9, 18, 19, 21, 22, 30, 35, 37,...</td>\n",
       "      <td>[0.7552380952380952, 0.7635714285714286, 0.734...</td>\n",
       "      <td>0.514905</td>\n",
       "      <td>(present_resid, age, chk_acct_A13, chk_acct_A1...</td>\n",
       "      <td>0.02951</td>\n",
       "      <td>0.039733</td>\n",
       "      <td>0.013244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(0, 1, 6, 7, 8, 9, 18, 19, 20, 21, 22, 30, 35,...</td>\n",
       "      <td>[0.7638095238095238, 0.7638095238095238, 0.720...</td>\n",
       "      <td>0.509524</td>\n",
       "      <td>(present_resid, age, chk_acct_A13, chk_acct_A1...</td>\n",
       "      <td>0.034433</td>\n",
       "      <td>0.046361</td>\n",
       "      <td>0.015454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(0, 1, 6, 7, 8, 9, 17, 18, 19, 20, 21, 22, 26,...</td>\n",
       "      <td>[0.7576190476190477, 0.7735714285714286, 0.748...</td>\n",
       "      <td>0.513286</td>\n",
       "      <td>(present_resid, age, chk_acct_A13, chk_acct_A1...</td>\n",
       "      <td>0.026255</td>\n",
       "      <td>0.03535</td>\n",
       "      <td>0.011783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(0, 1, 2, 6, 7, 8, 9, 17, 18, 19, 20, 21, 22, ...</td>\n",
       "      <td>[0.7547619047619049, 0.7697619047619048, 0.719...</td>\n",
       "      <td>0.514714</td>\n",
       "      <td>(present_resid, age, n_credits, chk_acct_A13, ...</td>\n",
       "      <td>0.029871</td>\n",
       "      <td>0.040219</td>\n",
       "      <td>0.013406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(0, 1, 2, 6, 7, 8, 9, 17, 18, 19, 20, 21, 22, ...</td>\n",
       "      <td>[0.7452380952380951, 0.7607142857142858, 0.715...</td>\n",
       "      <td>0.51381</td>\n",
       "      <td>(present_resid, age, n_credits, chk_acct_A13, ...</td>\n",
       "      <td>0.030996</td>\n",
       "      <td>0.041734</td>\n",
       "      <td>0.013911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(0, 1, 2, 3, 6, 7, 8, 9, 17, 18, 19, 20, 21, 2...</td>\n",
       "      <td>[0.7671428571428572, 0.7642857142857143, 0.735...</td>\n",
       "      <td>0.51519</td>\n",
       "      <td>(present_resid, age, n_credits, n_people, chk_...</td>\n",
       "      <td>0.032664</td>\n",
       "      <td>0.04398</td>\n",
       "      <td>0.01466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(0, 1, 2, 3, 6, 7, 8, 9, 17, 18, 19, 20, 22, 2...</td>\n",
       "      <td>[0.7771428571428571, 0.7614285714285715, 0.730...</td>\n",
       "      <td>0.522286</td>\n",
       "      <td>(present_resid, age, n_credits, n_people, chk_...</td>\n",
       "      <td>0.035401</td>\n",
       "      <td>0.047665</td>\n",
       "      <td>0.015888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(0, 1, 2, 3, 6, 7, 8, 9, 17, 18, 19, 20, 22, 2...</td>\n",
       "      <td>[0.769047619047619, 0.7642857142857142, 0.7376...</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>(present_resid, age, n_credits, n_people, chk_...</td>\n",
       "      <td>0.033804</td>\n",
       "      <td>0.045514</td>\n",
       "      <td>0.015171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(0, 1, 2, 3, 6, 7, 8, 9, 17, 18, 19, 20, 22, 2...</td>\n",
       "      <td>[0.7633333333333334, 0.7590476190476191, 0.732...</td>\n",
       "      <td>0.512571</td>\n",
       "      <td>(present_resid, age, n_credits, n_people, chk_...</td>\n",
       "      <td>0.033631</td>\n",
       "      <td>0.045282</td>\n",
       "      <td>0.015094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(0, 1, 2, 3, 6, 7, 8, 9, 17, 18, 19, 20, 22, 2...</td>\n",
       "      <td>[0.7576190476190477, 0.7604761904761904, 0.730...</td>\n",
       "      <td>0.514857</td>\n",
       "      <td>(present_resid, age, n_credits, n_people, chk_...</td>\n",
       "      <td>0.033813</td>\n",
       "      <td>0.045526</td>\n",
       "      <td>0.015175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          feature_idx  \\\n",
       "1                                                (7,)   \n",
       "2                                             (7, 35)   \n",
       "3                                         (7, 22, 35)   \n",
       "4                                      (6, 7, 22, 35)   \n",
       "5                                  (6, 7, 22, 35, 41)   \n",
       "6                              (6, 7, 22, 30, 35, 41)   \n",
       "7                          (6, 7, 22, 30, 35, 38, 41)   \n",
       "8                       (1, 6, 7, 22, 30, 35, 38, 41)   \n",
       "9                   (1, 6, 7, 18, 22, 30, 35, 38, 41)   \n",
       "10               (1, 6, 7, 8, 18, 22, 30, 35, 38, 41)   \n",
       "11            (0, 1, 6, 7, 8, 18, 22, 30, 35, 38, 41)   \n",
       "12        (0, 1, 6, 7, 8, 18, 22, 30, 35, 38, 41, 42)   \n",
       "13    (0, 1, 6, 7, 8, 18, 21, 22, 30, 35, 38, 41, 42)   \n",
       "14  (0, 1, 6, 7, 8, 18, 19, 21, 22, 30, 35, 38, 41...   \n",
       "15  (0, 1, 6, 7, 8, 9, 18, 19, 21, 22, 30, 35, 38,...   \n",
       "16  (0, 1, 6, 7, 8, 9, 18, 19, 21, 22, 30, 35, 37,...   \n",
       "17  (0, 1, 6, 7, 8, 9, 18, 19, 20, 21, 22, 30, 35,...   \n",
       "18  (0, 1, 6, 7, 8, 9, 17, 18, 19, 20, 21, 22, 26,...   \n",
       "19  (0, 1, 2, 6, 7, 8, 9, 17, 18, 19, 20, 21, 22, ...   \n",
       "20  (0, 1, 2, 6, 7, 8, 9, 17, 18, 19, 20, 21, 22, ...   \n",
       "21  (0, 1, 2, 3, 6, 7, 8, 9, 17, 18, 19, 20, 21, 2...   \n",
       "22  (0, 1, 2, 3, 6, 7, 8, 9, 17, 18, 19, 20, 22, 2...   \n",
       "23  (0, 1, 2, 3, 6, 7, 8, 9, 17, 18, 19, 20, 22, 2...   \n",
       "24  (0, 1, 2, 3, 6, 7, 8, 9, 17, 18, 19, 20, 22, 2...   \n",
       "25  (0, 1, 2, 3, 6, 7, 8, 9, 17, 18, 19, 20, 22, 2...   \n",
       "\n",
       "                                            cv_scores avg_score  \\\n",
       "1   [0.7095238095238096, 0.7142857142857143, 0.647...   0.34381   \n",
       "2   [0.7547619047619046, 0.7121428571428572, 0.658...  0.406381   \n",
       "3   [0.7607142857142858, 0.7559523809523809, 0.688...  0.435667   \n",
       "4   [0.7711904761904762, 0.771904761904762, 0.6902...     0.446   \n",
       "5   [0.793809523809524, 0.7566666666666667, 0.7026...  0.466381   \n",
       "6   [0.7904761904761906, 0.7823809523809524, 0.742...  0.474238   \n",
       "7   [0.7816666666666666, 0.7635714285714285, 0.717...  0.476333   \n",
       "8   [0.7692857142857142, 0.7419047619047618, 0.715...  0.491238   \n",
       "9   [0.7752380952380952, 0.7616666666666666, 0.708...  0.498048   \n",
       "10  [0.779047619047619, 0.7773809523809524, 0.7173...  0.507762   \n",
       "11  [0.7538095238095236, 0.799047619047619, 0.7266...  0.507571   \n",
       "12  [0.7547619047619047, 0.777142857142857, 0.7273...     0.509   \n",
       "13  [0.7576190476190476, 0.7783333333333333, 0.740...  0.512095   \n",
       "14  [0.7552380952380953, 0.7745238095238094, 0.734...  0.510429   \n",
       "15  [0.772857142857143, 0.7747619047619048, 0.7321...  0.516905   \n",
       "16  [0.7552380952380952, 0.7635714285714286, 0.734...  0.514905   \n",
       "17  [0.7638095238095238, 0.7638095238095238, 0.720...  0.509524   \n",
       "18  [0.7576190476190477, 0.7735714285714286, 0.748...  0.513286   \n",
       "19  [0.7547619047619049, 0.7697619047619048, 0.719...  0.514714   \n",
       "20  [0.7452380952380951, 0.7607142857142858, 0.715...   0.51381   \n",
       "21  [0.7671428571428572, 0.7642857142857143, 0.735...   0.51519   \n",
       "22  [0.7771428571428571, 0.7614285714285715, 0.730...  0.522286   \n",
       "23  [0.769047619047619, 0.7642857142857142, 0.7376...  0.514286   \n",
       "24  [0.7633333333333334, 0.7590476190476191, 0.732...  0.512571   \n",
       "25  [0.7576190476190477, 0.7604761904761904, 0.730...  0.514857   \n",
       "\n",
       "                                        feature_names  ci_bound   std_dev  \\\n",
       "1                                     (chk_acct_A14,)  0.031383  0.042255   \n",
       "2                       (chk_acct_A14, property_A121)  0.044722  0.060214   \n",
       "3      (chk_acct_A14, saving_acct_A65, property_A121)  0.031763  0.042767   \n",
       "4   (chk_acct_A13, chk_acct_A14, saving_acct_A65, ...  0.034671  0.046682   \n",
       "5   (chk_acct_A13, chk_acct_A14, saving_acct_A65, ...  0.038801  0.052242   \n",
       "6   (chk_acct_A13, chk_acct_A14, saving_acct_A65, ...  0.042182  0.056794   \n",
       "7   (chk_acct_A13, chk_acct_A14, saving_acct_A65, ...  0.040088  0.053975   \n",
       "8   (age, chk_acct_A13, chk_acct_A14, saving_acct_...  0.037816  0.050916   \n",
       "9   (age, chk_acct_A13, chk_acct_A14, saving_acct_...  0.028149    0.0379   \n",
       "10  (age, chk_acct_A13, chk_acct_A14, purpose_A40,...  0.031155  0.041947   \n",
       "11  (present_resid, age, chk_acct_A13, chk_acct_A1...   0.03212  0.043247   \n",
       "12  (present_resid, age, chk_acct_A13, chk_acct_A1...  0.031651  0.042616   \n",
       "13  (present_resid, age, chk_acct_A13, chk_acct_A1...   0.03214  0.043274   \n",
       "14  (present_resid, age, chk_acct_A13, chk_acct_A1...  0.031274  0.042108   \n",
       "15  (present_resid, age, chk_acct_A13, chk_acct_A1...  0.030446  0.040993   \n",
       "16  (present_resid, age, chk_acct_A13, chk_acct_A1...   0.02951  0.039733   \n",
       "17  (present_resid, age, chk_acct_A13, chk_acct_A1...  0.034433  0.046361   \n",
       "18  (present_resid, age, chk_acct_A13, chk_acct_A1...  0.026255   0.03535   \n",
       "19  (present_resid, age, n_credits, chk_acct_A13, ...  0.029871  0.040219   \n",
       "20  (present_resid, age, n_credits, chk_acct_A13, ...  0.030996  0.041734   \n",
       "21  (present_resid, age, n_credits, n_people, chk_...  0.032664   0.04398   \n",
       "22  (present_resid, age, n_credits, n_people, chk_...  0.035401  0.047665   \n",
       "23  (present_resid, age, n_credits, n_people, chk_...  0.033804  0.045514   \n",
       "24  (present_resid, age, n_credits, n_people, chk_...  0.033631  0.045282   \n",
       "25  (present_resid, age, n_credits, n_people, chk_...  0.033813  0.045526   \n",
       "\n",
       "     std_err  \n",
       "1   0.014085  \n",
       "2   0.020071  \n",
       "3   0.014256  \n",
       "4   0.015561  \n",
       "5   0.017414  \n",
       "6   0.018931  \n",
       "7   0.017992  \n",
       "8   0.016972  \n",
       "9   0.012633  \n",
       "10  0.013982  \n",
       "11  0.014416  \n",
       "12  0.014205  \n",
       "13  0.014425  \n",
       "14  0.014036  \n",
       "15  0.013664  \n",
       "16  0.013244  \n",
       "17  0.015454  \n",
       "18  0.011783  \n",
       "19  0.013406  \n",
       "20  0.013911  \n",
       "21   0.01466  \n",
       "22  0.015888  \n",
       "23  0.015171  \n",
       "24  0.015094  \n",
       "25  0.015175  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "results[\"avg_score\"] = results[\"avg_score\"] * 2 - 1\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['present_resid',\n",
       " 'age',\n",
       " 'chk_acct_A13',\n",
       " 'chk_acct_A14',\n",
       " 'purpose_A40',\n",
       " 'purpose_A41',\n",
       " 'saving_acct_A61',\n",
       " 'saving_acct_A62',\n",
       " 'saving_acct_A64',\n",
       " 'saving_acct_A65',\n",
       " 'sex_A93',\n",
       " 'property_A121',\n",
       " 'property_A124',\n",
       " 'other_install_A143',\n",
       " 'housing_A151']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_variables = list(results[\"feature_names\"][15])\n",
    "final_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_fin = xgb.DMatrix(X[final_variables], label=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-26 00:18:18,730]\u001b[0m A new study created in memory with name: no-name-2d44b74e-6f54-4128-b48d-0c6456f95b34\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MAX_ROUNDS = 1000\n",
    "CV_SPLITS = 10\n",
    "EARLY_STOPPING_ROUNDS = 50\n",
    "SEED = 42\n",
    "\n",
    "auc_monit = 0.5\n",
    "\n",
    "\n",
    "def objective(trial, build_name):\n",
    "    global auc_monit\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-8, 1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 14),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 50),\n",
    "        \"gamma\": trial.suggest_uniform(\"gamma\", 0, 10),\n",
    "        \"reg_alpha\": trial.suggest_uniform(\"reg_alpha\", 0, 10),\n",
    "        \"reg_lambda\": trial.suggest_uniform(\"reg_lambda\", 0, 10),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.3, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.3, 0.9),\n",
    "        \"colsample_bylevel\": trial.suggest_uniform(\"colsample_bylevel\", 0.3, 0.9),\n",
    "        \"colsample_bynode\": trial.suggest_uniform(\"colsample_bynode\", 0.3, 0.9),\n",
    "        \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 1, 10),\n",
    "        \"scale_pos_weight\": trial.suggest_int(\"scale_pos_weight\", 1, 8)\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"test-auc\")\n",
    "    xgb_cv_results = xgb.cv(\n",
    "        params=param,\n",
    "        dtrain=dtrain_fin,\n",
    "        stratified=True,\n",
    "        nfold=CV_SPLITS,\n",
    "        num_boost_round=MAX_ROUNDS,\n",
    "        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "        verbose_eval=False,\n",
    "        seed=SEED,\n",
    "        callbacks=[pruning_callback],\n",
    "    )\n",
    "\n",
    "    n_estimators = len(xgb_cv_results)\n",
    "    param[\"n_estimators\"] = n_estimators\n",
    "    trial.set_user_attr(\"n_estimators\", n_estimators)\n",
    "\n",
    "    mean_train_auc = xgb_cv_results[\"train-auc-mean\"].values[-1]\n",
    "    mean_val_auc = xgb_cv_results[\"test-auc-mean\"].values[-1]\n",
    "\n",
    "    if mean_val_auc > auc_monit:\n",
    "        auc_monit = mean_val_auc\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%H%M%S\")\n",
    "        snapshot_name = f\"T{timestamp} {trial.number:01d} [{np.round(mean_train_auc * 2 - 1, 3)} {np.round(mean_val_auc * 2 - 1, 3)}].json\"\n",
    "        json.dump(param, open(os.path.join(\"Builds\", build_name, snapshot_name), \"w\"))\n",
    "\n",
    "    return mean_val_auc * 2 - 1\n",
    "\n",
    "\n",
    "BUILD_NAME = datetime.now().strftime(\"%Y%m%d_T%H%M%S\") + \"_German_data_fin\"\n",
    "os.mkdir(os.path.join(\"Builds\", BUILD_NAME))\n",
    "\n",
    "study = optuna.create_study(directions=[\"maximize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-04-26 00:18:21,215]\u001b[0m Trial 1 finished with value: 0.0 and parameters: {'learning_rate': 0.0012728449267426518, 'max_depth': 14, 'min_child_weight': 22, 'gamma': 9.142398962555296, 'reg_alpha': 8.870668557260938, 'reg_lambda': 5.389929617171042, 'subsample': 0.5182336625719494, 'colsample_bytree': 0.7122352643618524, 'colsample_bylevel': 0.33766173600386407, 'colsample_bynode': 0.7576903708951668, 'max_delta_step': 6, 'scale_pos_weight': 6}. Best is trial 1 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:21,246]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'learning_rate': 0.9023502870513389, 'max_depth': 7, 'min_child_weight': 50, 'gamma': 9.453835180954062, 'reg_alpha': 1.5428006119976512, 'reg_lambda': 5.657016004355496, 'subsample': 0.420969145453254, 'colsample_bytree': 0.8791958851953521, 'colsample_bylevel': 0.5906908525294863, 'colsample_bynode': 0.4443212757933548, 'max_delta_step': 7, 'scale_pos_weight': 1}. Best is trial 1 with value: 0.0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:22,229]\u001b[0m Trial 2 finished with value: 0.34380960000000016 and parameters: {'learning_rate': 3.706256641951209e-08, 'max_depth': 11, 'min_child_weight': 26, 'gamma': 5.335284156748685, 'reg_alpha': 7.58739558087644, 'reg_lambda': 3.99103830442919, 'subsample': 0.5572093431343854, 'colsample_bytree': 0.3226321936473378, 'colsample_bylevel': 0.7141994954653612, 'colsample_bynode': 0.31825404362831855, 'max_delta_step': 4, 'scale_pos_weight': 3}. Best is trial 2 with value: 0.34380960000000016.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:22,466]\u001b[0m Trial 5 finished with value: 0.0 and parameters: {'learning_rate': 0.005742366042322896, 'max_depth': 13, 'min_child_weight': 22, 'gamma': 4.058779452175244, 'reg_alpha': 5.357431882865943, 'reg_lambda': 7.822194471094771, 'subsample': 0.36403454755078934, 'colsample_bytree': 0.6540492703781633, 'colsample_bylevel': 0.5341811034024009, 'colsample_bynode': 0.6497925482396492, 'max_delta_step': 4, 'scale_pos_weight': 7}. Best is trial 2 with value: 0.34380960000000016.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:23,650]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'learning_rate': 0.0010111755754924436, 'max_depth': 4, 'min_child_weight': 38, 'gamma': 9.284863439389548, 'reg_alpha': 6.725242202354858, 'reg_lambda': 8.039682882967295, 'subsample': 0.5714529651802163, 'colsample_bytree': 0.7397701401500147, 'colsample_bylevel': 0.5459327815129807, 'colsample_bynode': 0.6863199878979304, 'max_delta_step': 5, 'scale_pos_weight': 6}. Best is trial 2 with value: 0.34380960000000016.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:24,185]\u001b[0m Trial 4 finished with value: 0.3805236000000001 and parameters: {'learning_rate': 1.0361955061754027e-06, 'max_depth': 4, 'min_child_weight': 27, 'gamma': 3.4782343037711225, 'reg_alpha': 2.393172289044141, 'reg_lambda': 7.306459560582871, 'subsample': 0.37294495219628016, 'colsample_bytree': 0.8525467826552904, 'colsample_bylevel': 0.3464978003192961, 'colsample_bynode': 0.7800854682326939, 'max_delta_step': 6, 'scale_pos_weight': 2}. Best is trial 4 with value: 0.3805236000000001.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:24,766]\u001b[0m Trial 0 finished with value: 0.47971419999999987 and parameters: {'learning_rate': 0.0007692126244412848, 'max_depth': 4, 'min_child_weight': 33, 'gamma': 4.920583984875909, 'reg_alpha': 0.2559065980485953, 'reg_lambda': 0.1613429733145777, 'subsample': 0.6016896192948176, 'colsample_bytree': 0.6019728163427749, 'colsample_bylevel': 0.6945043623217332, 'colsample_bynode': 0.6101559676325264, 'max_delta_step': 4, 'scale_pos_weight': 7}. Best is trial 0 with value: 0.47971419999999987.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:25,758]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 120.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:26,165]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 95.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:26,382]\u001b[0m Trial 9 finished with value: 0.44866660000000014 and parameters: {'learning_rate': 0.8509277935392165, 'max_depth': 12, 'min_child_weight': 34, 'gamma': 0.2576909048361009, 'reg_alpha': 6.064730855554839, 'reg_lambda': 0.8400301325828863, 'subsample': 0.533589861916077, 'colsample_bytree': 0.5176509863387275, 'colsample_bylevel': 0.3180295492485921, 'colsample_bynode': 0.5828648190060818, 'max_delta_step': 4, 'scale_pos_weight': 2}. Best is trial 0 with value: 0.47971419999999987.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:26,543]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:26,801]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:27,869]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:29,108]\u001b[0m Trial 15 finished with value: 0.4720477999999999 and parameters: {'learning_rate': 0.959263850606148, 'max_depth': 8, 'min_child_weight': 38, 'gamma': 0.27771893135200454, 'reg_alpha': 0.13121375607179875, 'reg_lambda': 0.028495327484902855, 'subsample': 0.693759583497055, 'colsample_bytree': 0.5263431855903447, 'colsample_bylevel': 0.8804588170104934, 'colsample_bynode': 0.5480529729027082, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 0 with value: 0.47971419999999987.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:29,254]\u001b[0m Trial 14 finished with value: 0.4771426000000001 and parameters: {'learning_rate': 0.7444005262495188, 'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.1666586064169343, 'reg_alpha': 0.11063195135044632, 'reg_lambda': 0.06918341516704285, 'subsample': 0.7589928157611385, 'colsample_bytree': 0.5326712010802864, 'colsample_bylevel': 0.8790150796514711, 'colsample_bynode': 0.5183706822081854, 'max_delta_step': 1, 'scale_pos_weight': 4}. Best is trial 0 with value: 0.47971419999999987.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:29,481]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:29,984]\u001b[0m Trial 10 finished with value: 0.49638099999999996 and parameters: {'learning_rate': 0.4279710594690675, 'max_depth': 3, 'min_child_weight': 5, 'gamma': 8.645954699162097, 'reg_alpha': 7.8748983397721375, 'reg_lambda': 4.59462068246077, 'subsample': 0.5958483412205846, 'colsample_bytree': 0.3191489656191528, 'colsample_bylevel': 0.722328092779611, 'colsample_bynode': 0.5699871696572081, 'max_delta_step': 1, 'scale_pos_weight': 8}. Best is trial 10 with value: 0.49638099999999996.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:30,271]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:30,571]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:30,845]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:31,116]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:31,737]\u001b[0m Trial 16 finished with value: 0.47966679999999995 and parameters: {'learning_rate': 0.7656318739777261, 'max_depth': 7, 'min_child_weight': 34, 'gamma': 0.7248189333980628, 'reg_alpha': 0.07945627017494328, 'reg_lambda': 0.18986548137601325, 'subsample': 0.6934998942091072, 'colsample_bytree': 0.4882563310591739, 'colsample_bylevel': 0.4567357503528855, 'colsample_bynode': 0.5428135402666333, 'max_delta_step': 2, 'scale_pos_weight': 4}. Best is trial 10 with value: 0.49638099999999996.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:33,147]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 55.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:33,359]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:34,770]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:34,979]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:35,369]\u001b[0m Trial 17 finished with value: 0.5254285999999999 and parameters: {'learning_rate': 0.044733263194384525, 'max_depth': 7, 'min_child_weight': 13, 'gamma': 0.055811319375159485, 'reg_alpha': 0.08930771193389364, 'reg_lambda': 2.154196107543935, 'subsample': 0.6990690429402302, 'colsample_bytree': 0.5268131203787203, 'colsample_bylevel': 0.875632603982315, 'colsample_bynode': 0.5291477827362306, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 17 with value: 0.5254285999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:35,759]\u001b[0m Trial 24 finished with value: 0.4964286000000002 and parameters: {'learning_rate': 0.21379103864827068, 'max_depth': 10, 'min_child_weight': 1, 'gamma': 1.2800436777129498, 'reg_alpha': 1.0311849710732748, 'reg_lambda': 1.2719505575707237, 'subsample': 0.7532104361227344, 'colsample_bytree': 0.6108655637873027, 'colsample_bylevel': 0.8936186272836322, 'colsample_bynode': 0.5252813538342456, 'max_delta_step': 1, 'scale_pos_weight': 4}. Best is trial 17 with value: 0.5254285999999999.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:36,766]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:37,606]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 55.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:37,825]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:38,029]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:38,549]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:38,904]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:39,671]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:40,499]\u001b[0m Trial 19 finished with value: 0.5267142000000002 and parameters: {'learning_rate': 0.08057285541855698, 'max_depth': 9, 'min_child_weight': 15, 'gamma': 1.6141106391884494, 'reg_alpha': 3.729813495727347, 'reg_lambda': 1.8154809631851498, 'subsample': 0.6993002082977554, 'colsample_bytree': 0.5725426526136381, 'colsample_bylevel': 0.8791300881830542, 'colsample_bynode': 0.523874149508356, 'max_delta_step': 2, 'scale_pos_weight': 4}. Best is trial 19 with value: 0.5267142000000002.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:40,703]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:40,907]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:41,525]\u001b[0m Trial 32 finished with value: 0.5292858000000003 and parameters: {'learning_rate': 0.16354835175288282, 'max_depth': 10, 'min_child_weight': 1, 'gamma': 1.4943756471440084, 'reg_alpha': 2.864989364683045, 'reg_lambda': 3.08701328990836, 'subsample': 0.766297604135939, 'colsample_bytree': 0.7113924634189429, 'colsample_bylevel': 0.8947805372798919, 'colsample_bynode': 0.3692151752881054, 'max_delta_step': 9, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:42,661]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 33.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:42,904]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:43,080]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 157.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:43,327]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:45,263]\u001b[0m Trial 41 finished with value: 0.5116187999999999 and parameters: {'learning_rate': 0.3581454661730044, 'max_depth': 11, 'min_child_weight': 20, 'gamma': 3.083922699973582, 'reg_alpha': 7.062474725484424, 'reg_lambda': 4.826206622872, 'subsample': 0.7414030554941698, 'colsample_bytree': 0.48528520733933334, 'colsample_bylevel': 0.8888577469010297, 'colsample_bynode': 0.5163769498712681, 'max_delta_step': 2, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:45,563]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:46,157]\u001b[0m Trial 46 finished with value: 0.5286187999999998 and parameters: {'learning_rate': 0.4148821061290892, 'max_depth': 9, 'min_child_weight': 7, 'gamma': 3.379727359703125, 'reg_alpha': 3.977695507867217, 'reg_lambda': 3.632020045196392, 'subsample': 0.6738083419801569, 'colsample_bytree': 0.8337480368608081, 'colsample_bylevel': 0.6269964445213843, 'colsample_bynode': 0.6442538204511806, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:46,576]\u001b[0m Trial 45 finished with value: 0.5291906 and parameters: {'learning_rate': 0.3208381388446698, 'max_depth': 11, 'min_child_weight': 5, 'gamma': 0.0057779842435807804, 'reg_alpha': 4.731979219730491, 'reg_lambda': 4.8140925932390894, 'subsample': 0.759126451193098, 'colsample_bytree': 0.7808662566986713, 'colsample_bylevel': 0.8989267420935863, 'colsample_bynode': 0.5762290492111113, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:46,801]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:47,804]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 157.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:48,261]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:49,545]\u001b[0m Trial 49 finished with value: 0.5097615999999998 and parameters: {'learning_rate': 0.43443577324414123, 'max_depth': 9, 'min_child_weight': 20, 'gamma': 4.012048333728726, 'reg_alpha': 5.981460508674784, 'reg_lambda': 3.830120262559322, 'subsample': 0.721939654220532, 'colsample_bytree': 0.852634721213946, 'colsample_bylevel': 0.6391858470461848, 'colsample_bynode': 0.6648021185882932, 'max_delta_step': 10, 'scale_pos_weight': 2}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:50,554]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 157.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:51,997]\u001b[0m Trial 54 finished with value: 0.5077144000000002 and parameters: {'learning_rate': 0.9814265798652894, 'max_depth': 12, 'min_child_weight': 14, 'gamma': 2.2552919039207904, 'reg_alpha': 4.800682602376769, 'reg_lambda': 4.890080224166151, 'subsample': 0.8407298889716935, 'colsample_bytree': 0.8960896113157217, 'colsample_bylevel': 0.8955466922952605, 'colsample_bynode': 0.5715354864348126, 'max_delta_step': 9, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:52,222]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:52,567]\u001b[0m Trial 53 finished with value: 0.5250476000000002 and parameters: {'learning_rate': 0.632264714976313, 'max_depth': 7, 'min_child_weight': 6, 'gamma': 2.412486776899558, 'reg_alpha': 5.020331086298862, 'reg_lambda': 5.723362546991, 'subsample': 0.8433055177523991, 'colsample_bytree': 0.889072845482978, 'colsample_bylevel': 0.7776821761183241, 'colsample_bynode': 0.6431810684883037, 'max_delta_step': 9, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:52,922]\u001b[0m Trial 51 pruned. Trial was pruned at iteration 157.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:53,449]\u001b[0m Trial 55 finished with value: 0.5175238 and parameters: {'learning_rate': 0.8615245031061033, 'max_depth': 13, 'min_child_weight': 6, 'gamma': 0.06145178869979417, 'reg_alpha': 4.951091802961182, 'reg_lambda': 5.62557759222542, 'subsample': 0.6630322129220413, 'colsample_bytree': 0.8924745199273182, 'colsample_bylevel': 0.7821072555691143, 'colsample_bynode': 0.5664333820413447, 'max_delta_step': 9, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:53,770]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:54,235]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:54,960]\u001b[0m Trial 57 finished with value: 0.5032854 and parameters: {'learning_rate': 0.951740314080832, 'max_depth': 13, 'min_child_weight': 15, 'gamma': 0.025249482866774333, 'reg_alpha': 5.2145684973576545, 'reg_lambda': 2.6672760380419898, 'subsample': 0.7000157919805583, 'colsample_bytree': 0.7518794699113841, 'colsample_bylevel': 0.7751928980563724, 'colsample_bynode': 0.6005978982761462, 'max_delta_step': 9, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:55,257]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:55,589]\u001b[0m Trial 58 finished with value: 0.5078572000000001 and parameters: {'learning_rate': 0.8282311169810144, 'max_depth': 7, 'min_child_weight': 9, 'gamma': 0.12787504103550795, 'reg_alpha': 5.199438318427883, 'reg_lambda': 6.127146686186074, 'subsample': 0.6971370207229906, 'colsample_bytree': 0.8824391890804794, 'colsample_bylevel': 0.771416574626248, 'colsample_bynode': 0.6000348109168634, 'max_delta_step': 9, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:56,083]\u001b[0m Trial 59 finished with value: 0.5135716000000001 and parameters: {'learning_rate': 0.8162335110758795, 'max_depth': 7, 'min_child_weight': 6, 'gamma': 2.7157952235666, 'reg_alpha': 5.145427851297849, 'reg_lambda': 6.52801416924207, 'subsample': 0.8965645122911624, 'colsample_bytree': 0.8774878882179048, 'colsample_bylevel': 0.7733455976729975, 'colsample_bynode': 0.5937288193021631, 'max_delta_step': 9, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:56,336]\u001b[0m Trial 66 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:57,031]\u001b[0m Trial 62 finished with value: 0.5036192000000002 and parameters: {'learning_rate': 0.9384119935948241, 'max_depth': 7, 'min_child_weight': 3, 'gamma': 2.007081131658126, 'reg_alpha': 5.170207396880288, 'reg_lambda': 2.6545901593843375, 'subsample': 0.86762710130721, 'colsample_bytree': 0.7975264775840751, 'colsample_bylevel': 0.8642457406457862, 'colsample_bynode': 0.6715652347772487, 'max_delta_step': 9, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:57,246]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:59,196]\u001b[0m Trial 65 finished with value: 0.5229522000000002 and parameters: {'learning_rate': 0.23657761381501588, 'max_depth': 14, 'min_child_weight': 6, 'gamma': 1.4822232984839239, 'reg_alpha': 4.74515824091822, 'reg_lambda': 6.517708016699047, 'subsample': 0.6507719279705625, 'colsample_bytree': 0.8968955840930267, 'colsample_bylevel': 0.7443206776613207, 'colsample_bynode': 0.6729339374949835, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:59,403]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:59,555]\u001b[0m Trial 67 finished with value: 0.5211904 and parameters: {'learning_rate': 0.5374962213138589, 'max_depth': 14, 'min_child_weight': 3, 'gamma': 1.4694310861114988, 'reg_alpha': 4.72339035509601, 'reg_lambda': 7.743722236946017, 'subsample': 0.7942936710813222, 'colsample_bytree': 0.8997295552920359, 'colsample_bylevel': 0.8074132451396138, 'colsample_bynode': 0.5507690587017597, 'max_delta_step': 8, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:18:59,815]\u001b[0m Trial 72 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:00,027]\u001b[0m Trial 73 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:00,440]\u001b[0m Trial 69 finished with value: 0.5171427999999998 and parameters: {'learning_rate': 0.4739612610554714, 'max_depth': 14, 'min_child_weight': 12, 'gamma': 0.4864121878437383, 'reg_alpha': 3.9268938295941846, 'reg_lambda': 3.360133123556159, 'subsample': 0.7904271769111822, 'colsample_bytree': 0.8976324672662905, 'colsample_bylevel': 0.7954930317400106, 'colsample_bynode': 0.5340871107114814, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:00,639]\u001b[0m Trial 75 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:00,838]\u001b[0m Trial 76 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:01,053]\u001b[0m Trial 77 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:01,250]\u001b[0m Trial 78 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:01,521]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:01,993]\u001b[0m Trial 64 finished with value: 0.5232853999999998 and parameters: {'learning_rate': 0.6281253919942347, 'max_depth': 14, 'min_child_weight': 6, 'gamma': 2.7218520255901746, 'reg_alpha': 5.121738197059182, 'reg_lambda': 6.7767669049498425, 'subsample': 0.6568997290671714, 'colsample_bytree': 0.8839476533693686, 'colsample_bylevel': 0.7984010670609916, 'colsample_bynode': 0.6684720305150642, 'max_delta_step': 9, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:02,199]\u001b[0m Trial 81 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:02,404]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:02,666]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:02,875]\u001b[0m Trial 84 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:03,624]\u001b[0m Trial 71 finished with value: 0.5108571999999998 and parameters: {'learning_rate': 0.5648455416497378, 'max_depth': 8, 'min_child_weight': 12, 'gamma': 2.414091285696599, 'reg_alpha': 3.3654489394185285, 'reg_lambda': 3.4269019467538953, 'subsample': 0.7939027005493836, 'colsample_bytree': 0.8701246793502786, 'colsample_bylevel': 0.7948486143564818, 'colsample_bynode': 0.6302531558931401, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:03,831]\u001b[0m Trial 86 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:04,198]\u001b[0m Trial 87 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:04,484]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:05,262]\u001b[0m Trial 74 finished with value: 0.5231428 and parameters: {'learning_rate': 0.487686113737642, 'max_depth': 14, 'min_child_weight': 3, 'gamma': 1.2828883687468338, 'reg_alpha': 5.611990010598193, 'reg_lambda': 7.179193337850634, 'subsample': 0.7892530067964536, 'colsample_bytree': 0.8995892055976954, 'colsample_bylevel': 0.8062633350470643, 'colsample_bynode': 0.5418089750365653, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:05,510]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:05,771]\u001b[0m Trial 91 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:05,982]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:06,193]\u001b[0m Trial 93 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:06,365]\u001b[0m Trial 85 finished with value: 0.5076664000000002 and parameters: {'learning_rate': 0.5573883290933183, 'max_depth': 14, 'min_child_weight': 5, 'gamma': 0.7800421416170625, 'reg_alpha': 4.911067953601607, 'reg_lambda': 2.394810023597428, 'subsample': 0.7313612491520096, 'colsample_bytree': 0.8989395565032913, 'colsample_bylevel': 0.6181280106953913, 'colsample_bynode': 0.699948933535764, 'max_delta_step': 8, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:08,053]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 165.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:08,698]\u001b[0m Trial 95 finished with value: 0.5283806 and parameters: {'learning_rate': 0.674739047011008, 'max_depth': 13, 'min_child_weight': 1, 'gamma': 1.4000053726600445, 'reg_alpha': 5.772065428729247, 'reg_lambda': 8.188109101250454, 'subsample': 0.8375876924231682, 'colsample_bytree': 0.856260387065052, 'colsample_bylevel': 0.8122700153445013, 'colsample_bynode': 0.5303872549238698, 'max_delta_step': 9, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:08,733]\u001b[0m Trial 89 finished with value: 0.5182857999999999 and parameters: {'learning_rate': 0.6234975785209086, 'max_depth': 6, 'min_child_weight': 6, 'gamma': 4.494613040534154, 'reg_alpha': 3.755404743120709, 'reg_lambda': 6.753274039267337, 'subsample': 0.6843196560409952, 'colsample_bytree': 0.8498679569235855, 'colsample_bylevel': 0.8782670459162532, 'colsample_bynode': 0.6199386110781046, 'max_delta_step': 9, 'scale_pos_weight': 5}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:09,066]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:09,387]\u001b[0m Trial 99 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:09,611]\u001b[0m Trial 94 finished with value: 0.5152858 and parameters: {'learning_rate': 0.6276243147254345, 'max_depth': 14, 'min_child_weight': 1, 'gamma': 0.9182955164755771, 'reg_alpha': 3.703483968723497, 'reg_lambda': 7.048817838387757, 'subsample': 0.823409225593088, 'colsample_bytree': 0.8626619776907873, 'colsample_bylevel': 0.8090542164983012, 'colsample_bynode': 0.5277468543351544, 'max_delta_step': 9, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:09,780]\u001b[0m Trial 100 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:09,959]\u001b[0m Trial 101 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:10,113]\u001b[0m Trial 102 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:10,296]\u001b[0m Trial 103 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:10,696]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 22.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:10,901]\u001b[0m Trial 106 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:11,168]\u001b[0m Trial 107 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:12,519]\u001b[0m Trial 96 finished with value: 0.5127143999999999 and parameters: {'learning_rate': 0.9952921390625937, 'max_depth': 13, 'min_child_weight': 2, 'gamma': 1.253184456977754, 'reg_alpha': 5.726513557300847, 'reg_lambda': 7.4226682094029375, 'subsample': 0.8022678109292412, 'colsample_bytree': 0.8616819229677496, 'colsample_bylevel': 0.757551950727962, 'colsample_bynode': 0.4993809346487471, 'max_delta_step': 9, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:12,869]\u001b[0m Trial 109 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:13,047]\u001b[0m Trial 104 finished with value: 0.5119046 and parameters: {'learning_rate': 0.8263986996484495, 'max_depth': 14, 'min_child_weight': 3, 'gamma': 1.3939494226266216, 'reg_alpha': 4.612501181252076, 'reg_lambda': 7.360585909733962, 'subsample': 0.7788540714754881, 'colsample_bytree': 0.8322867608455105, 'colsample_bylevel': 0.7941297773673271, 'colsample_bynode': 0.5422445378672867, 'max_delta_step': 9, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:13,238]\u001b[0m Trial 110 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:13,451]\u001b[0m Trial 112 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:13,630]\u001b[0m Trial 111 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:13,819]\u001b[0m Trial 105 finished with value: 0.5106194 and parameters: {'learning_rate': 0.8375731344897193, 'max_depth': 14, 'min_child_weight': 3, 'gamma': 1.2749615952217341, 'reg_alpha': 4.571423748904315, 'reg_lambda': 7.383140257296444, 'subsample': 0.7831861952783733, 'colsample_bytree': 0.8053309698076441, 'colsample_bylevel': 0.763259315543848, 'colsample_bynode': 0.561943956038577, 'max_delta_step': 9, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:14,031]\u001b[0m Trial 113 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:14,034]\u001b[0m Trial 114 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:14,358]\u001b[0m Trial 115 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:14,540]\u001b[0m Trial 116 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:14,568]\u001b[0m Trial 117 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:14,885]\u001b[0m Trial 118 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:15,101]\u001b[0m Trial 119 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:15,133]\u001b[0m Trial 120 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:15,451]\u001b[0m Trial 121 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:15,612]\u001b[0m Trial 123 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:15,811]\u001b[0m Trial 122 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:15,994]\u001b[0m Trial 108 finished with value: 0.5199048 and parameters: {'learning_rate': 0.7956802526728017, 'max_depth': 12, 'min_child_weight': 2, 'gamma': 0.29850771642655394, 'reg_alpha': 6.087186142401335, 'reg_lambda': 7.330884825119745, 'subsample': 0.7824449084746299, 'colsample_bytree': 0.6147775616276829, 'colsample_bylevel': 0.8070844133547542, 'colsample_bynode': 0.5520946857673072, 'max_delta_step': 8, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:16,167]\u001b[0m Trial 124 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:16,365]\u001b[0m Trial 127 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:16,470]\u001b[0m Trial 126 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:16,731]\u001b[0m Trial 129 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:16,837]\u001b[0m Trial 128 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:16,897]\u001b[0m Trial 130 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:17,212]\u001b[0m Trial 125 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:17,419]\u001b[0m Trial 131 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:17,545]\u001b[0m Trial 133 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:17,581]\u001b[0m Trial 132 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:17,922]\u001b[0m Trial 134 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:18,133]\u001b[0m Trial 137 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:18,306]\u001b[0m Trial 135 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:18,556]\u001b[0m Trial 136 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:18,790]\u001b[0m Trial 141 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:18,996]\u001b[0m Trial 140 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:19,431]\u001b[0m Trial 143 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:19,840]\u001b[0m Trial 144 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:21,421]\u001b[0m Trial 138 finished with value: 0.5187143999999999 and parameters: {'learning_rate': 0.3682316705578492, 'max_depth': 14, 'min_child_weight': 8, 'gamma': 1.9472699778242002, 'reg_alpha': 6.165207349936116, 'reg_lambda': 1.4785199302725465, 'subsample': 0.7661129472803319, 'colsample_bytree': 0.8733397958152144, 'colsample_bylevel': 0.7668565272138714, 'colsample_bynode': 0.5104515742947564, 'max_delta_step': 4, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:21,698]\u001b[0m Trial 139 finished with value: 0.5206665999999998 and parameters: {'learning_rate': 0.9727626806865143, 'max_depth': 13, 'min_child_weight': 11, 'gamma': 1.6425548868895041, 'reg_alpha': 6.529148578065934, 'reg_lambda': 5.273060024623562, 'subsample': 0.7691705963335793, 'colsample_bytree': 0.8728036936250079, 'colsample_bylevel': 0.7712511929861348, 'colsample_bynode': 0.6686398330273926, 'max_delta_step': 10, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:21,880]\u001b[0m Trial 142 finished with value: 0.5091901999999999 and parameters: {'learning_rate': 0.9848842657101543, 'max_depth': 10, 'min_child_weight': 8, 'gamma': 2.550859964173059, 'reg_alpha': 4.309685753663968, 'reg_lambda': 5.338626769020684, 'subsample': 0.6643971687200759, 'colsample_bytree': 0.8965793734469594, 'colsample_bylevel': 0.8114626666297052, 'colsample_bynode': 0.6038628688342557, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:22,229]\u001b[0m Trial 147 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:22,471]\u001b[0m Trial 149 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:22,935]\u001b[0m Trial 150 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:23,173]\u001b[0m Trial 151 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:23,568]\u001b[0m Trial 145 finished with value: 0.5193337999999998 and parameters: {'learning_rate': 0.5923894307371944, 'max_depth': 14, 'min_child_weight': 12, 'gamma': 1.463161725717692, 'reg_alpha': 4.371215132567468, 'reg_lambda': 3.6930777014207865, 'subsample': 0.7913683539790283, 'colsample_bytree': 0.8978590133799781, 'colsample_bylevel': 0.7972745520129688, 'colsample_bynode': 0.5326096635822752, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:23,815]\u001b[0m Trial 153 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:24,174]\u001b[0m Trial 154 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:24,433]\u001b[0m Trial 155 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:24,832]\u001b[0m Trial 156 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:25,062]\u001b[0m Trial 157 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:25,276]\u001b[0m Trial 146 finished with value: 0.5220478 and parameters: {'learning_rate': 0.6877884520866002, 'max_depth': 14, 'min_child_weight': 8, 'gamma': 1.4662206469075207, 'reg_alpha': 4.468039437134005, 'reg_lambda': 1.2048275423229278, 'subsample': 0.8370534417177368, 'colsample_bytree': 0.8440429938502542, 'colsample_bylevel': 0.7747336334524358, 'colsample_bynode': 0.5167131950248642, 'max_delta_step': 5, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:25,397]\u001b[0m Trial 158 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:25,655]\u001b[0m Trial 159 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:25,784]\u001b[0m Trial 160 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:26,032]\u001b[0m Trial 161 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:26,159]\u001b[0m Trial 162 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:26,427]\u001b[0m Trial 164 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:26,660]\u001b[0m Trial 165 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:26,857]\u001b[0m Trial 163 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:27,174]\u001b[0m Trial 166 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:27,313]\u001b[0m Trial 167 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:27,747]\u001b[0m Trial 168 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:28,002]\u001b[0m Trial 170 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:28,236]\u001b[0m Trial 171 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:29,021]\u001b[0m Trial 148 finished with value: 0.5218574 and parameters: {'learning_rate': 0.6131925963869084, 'max_depth': 14, 'min_child_weight': 10, 'gamma': 1.5272424430324363, 'reg_alpha': 6.2307585359545, 'reg_lambda': 1.2766617545199024, 'subsample': 0.8360520979477024, 'colsample_bytree': 0.8302399107916364, 'colsample_bylevel': 0.8995752703206569, 'colsample_bynode': 0.6961302672273124, 'max_delta_step': 4, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:29,391]\u001b[0m Trial 152 finished with value: 0.5190002 and parameters: {'learning_rate': 0.5806803199452515, 'max_depth': 6, 'min_child_weight': 5, 'gamma': 2.022851145286206, 'reg_alpha': 6.97440635783145, 'reg_lambda': 7.003990736929267, 'subsample': 0.7404712411232584, 'colsample_bytree': 0.8304181138552031, 'colsample_bylevel': 0.8988301297763033, 'colsample_bynode': 0.6990132826156497, 'max_delta_step': 3, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:29,512]\u001b[0m Trial 173 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:29,880]\u001b[0m Trial 175 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:30,118]\u001b[0m Trial 176 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:30,363]\u001b[0m Trial 177 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:31,047]\u001b[0m Trial 169 finished with value: 0.5218570000000002 and parameters: {'learning_rate': 0.9932725491522848, 'max_depth': 14, 'min_child_weight': 7, 'gamma': 1.7909568130510534, 'reg_alpha': 4.509867511354731, 'reg_lambda': 6.752070859912252, 'subsample': 0.7662860571062671, 'colsample_bytree': 0.8521719954442397, 'colsample_bylevel': 0.8289556640750934, 'colsample_bynode': 0.6621541980671374, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:32,741]\u001b[0m Trial 172 finished with value: 0.5166665999999998 and parameters: {'learning_rate': 0.5718027932429666, 'max_depth': 6, 'min_child_weight': 10, 'gamma': 3.0852372361424747, 'reg_alpha': 4.711229244798425, 'reg_lambda': 0.5115504453920071, 'subsample': 0.6969180626143833, 'colsample_bytree': 0.868236009459833, 'colsample_bylevel': 0.8307730659052411, 'colsample_bynode': 0.6249563989343189, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:33,235]\u001b[0m Trial 174 finished with value: 0.5229047999999998 and parameters: {'learning_rate': 0.5031351457454397, 'max_depth': 14, 'min_child_weight': 11, 'gamma': 1.4715068888493181, 'reg_alpha': 6.283118854435939, 'reg_lambda': 0.4665660558888278, 'subsample': 0.7610407574023894, 'colsample_bytree': 0.820624467203138, 'colsample_bylevel': 0.8928198759274091, 'colsample_bynode': 0.6970431329334684, 'max_delta_step': 2, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:33,758]\u001b[0m Trial 179 finished with value: 0.5193810000000001 and parameters: {'learning_rate': 0.9718214194190354, 'max_depth': 13, 'min_child_weight': 4, 'gamma': 0.8523012939330294, 'reg_alpha': 8.327703403378209, 'reg_lambda': 7.285937432603067, 'subsample': 0.7926103556292723, 'colsample_bytree': 0.8370523000036467, 'colsample_bylevel': 0.8639508287888819, 'colsample_bynode': 0.7372373643082716, 'max_delta_step': 5, 'scale_pos_weight': 3}. Best is trial 32 with value: 0.5292858000000003.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:34,202]\u001b[0m Trial 181 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:34,471]\u001b[0m Trial 183 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:34,738]\u001b[0m Trial 178 finished with value: 0.5387142 and parameters: {'learning_rate': 0.3208371150697334, 'max_depth': 14, 'min_child_weight': 8, 'gamma': 0.7710546555883082, 'reg_alpha': 6.363149955199062, 'reg_lambda': 0.5434369357798852, 'subsample': 0.7830182955045133, 'colsample_bytree': 0.820911303385816, 'colsample_bylevel': 0.7749767494583143, 'colsample_bynode': 0.6886742024787154, 'max_delta_step': 3, 'scale_pos_weight': 3}. Best is trial 178 with value: 0.5387142.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:35,003]\u001b[0m Trial 182 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:35,234]\u001b[0m Trial 186 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:35,580]\u001b[0m Trial 185 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:35,827]\u001b[0m Trial 188 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:36,102]\u001b[0m Trial 189 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:36,346]\u001b[0m Trial 190 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:37,126]\u001b[0m Trial 180 finished with value: 0.5207142 and parameters: {'learning_rate': 0.9529449307475374, 'max_depth': 13, 'min_child_weight': 4, 'gamma': 0.9198450519194215, 'reg_alpha': 5.314633457267179, 'reg_lambda': 7.133470797319932, 'subsample': 0.7858961842171744, 'colsample_bytree': 0.819226208574444, 'colsample_bylevel': 0.864242162857007, 'colsample_bynode': 0.6862714791585619, 'max_delta_step': 3, 'scale_pos_weight': 2}. Best is trial 178 with value: 0.5387142.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:37,378]\u001b[0m Trial 192 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:37,683]\u001b[0m Trial 193 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:37,941]\u001b[0m Trial 194 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:38,195]\u001b[0m Trial 195 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:38,827]\u001b[0m Trial 184 finished with value: 0.5149525999999998 and parameters: {'learning_rate': 0.9646618786128771, 'max_depth': 14, 'min_child_weight': 12, 'gamma': 1.2610336540003513, 'reg_alpha': 5.361205565319009, 'reg_lambda': 7.746870850880835, 'subsample': 0.7825398399089167, 'colsample_bytree': 0.8564979673604101, 'colsample_bylevel': 0.8774376024598649, 'colsample_bynode': 0.6716607659718008, 'max_delta_step': 5, 'scale_pos_weight': 3}. Best is trial 178 with value: 0.5387142.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:39,107]\u001b[0m Trial 197 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:39,391]\u001b[0m Trial 187 finished with value: 0.5243812000000001 and parameters: {'learning_rate': 0.9604163597462648, 'max_depth': 14, 'min_child_weight': 9, 'gamma': 1.086961299312585, 'reg_alpha': 8.013871109120355, 'reg_lambda': 7.543142279864948, 'subsample': 0.7830961577002504, 'colsample_bytree': 0.8483914411403365, 'colsample_bylevel': 0.8839713167924461, 'colsample_bynode': 0.7178176173895015, 'max_delta_step': 3, 'scale_pos_weight': 3}. Best is trial 178 with value: 0.5387142.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:39,411]\u001b[0m Trial 198 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:39,951]\u001b[0m Trial 200 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:40,186]\u001b[0m Trial 199 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:40,399]\u001b[0m Trial 201 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:40,623]\u001b[0m Trial 202 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:40,820]\u001b[0m Trial 203 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:41,162]\u001b[0m Trial 205 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:41,422]\u001b[0m Trial 206 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:41,669]\u001b[0m Trial 207 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:41,995]\u001b[0m Trial 208 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:42,281]\u001b[0m Trial 209 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:43,249]\u001b[0m Trial 196 finished with value: 0.5120954000000002 and parameters: {'learning_rate': 0.7491993045919039, 'max_depth': 13, 'min_child_weight': 8, 'gamma': 1.243922322070977, 'reg_alpha': 4.970246966923567, 'reg_lambda': 6.900834119361705, 'subsample': 0.770772980023949, 'colsample_bytree': 0.8545783593626689, 'colsample_bylevel': 0.8914812151285909, 'colsample_bynode': 0.7668112746076927, 'max_delta_step': 2, 'scale_pos_weight': 3}. Best is trial 178 with value: 0.5387142.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:44,441]\u001b[0m Trial 204 finished with value: 0.5166187999999998 and parameters: {'learning_rate': 0.8137493373313089, 'max_depth': 13, 'min_child_weight': 7, 'gamma': 1.2851722047553455, 'reg_alpha': 8.090605835214879, 'reg_lambda': 8.278758397437223, 'subsample': 0.799674107693339, 'colsample_bytree': 0.8503963393308377, 'colsample_bylevel': 0.8660572659862169, 'colsample_bynode': 0.7443164096676538, 'max_delta_step': 10, 'scale_pos_weight': 3}. Best is trial 178 with value: 0.5387142.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:44,771]\u001b[0m Trial 191 finished with value: 0.5301906000000001 and parameters: {'learning_rate': 0.433332131728079, 'max_depth': 14, 'min_child_weight': 9, 'gamma': 1.1674134858047742, 'reg_alpha': 9.135756020648643, 'reg_lambda': 0.13817917622360681, 'subsample': 0.8414353678792307, 'colsample_bytree': 0.850007247258302, 'colsample_bylevel': 0.861624677657825, 'colsample_bynode': 0.6524787519554056, 'max_delta_step': 3, 'scale_pos_weight': 3}. Best is trial 178 with value: 0.5387142.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:44,903]\u001b[0m Trial 210 finished with value: 0.5208569999999999 and parameters: {'learning_rate': 0.6878481477260936, 'max_depth': 12, 'min_child_weight': 7, 'gamma': 1.4561045352412796, 'reg_alpha': 8.49723959293081, 'reg_lambda': 1.0748991964512216, 'subsample': 0.760001014602266, 'colsample_bytree': 0.8872936984827824, 'colsample_bylevel': 0.7731345583546351, 'colsample_bynode': 0.6721023632907286, 'max_delta_step': 10, 'scale_pos_weight': 2}. Best is trial 178 with value: 0.5387142.\u001b[0m\n",
      "\u001b[32m[I 2021-04-26 00:19:45,440]\u001b[0m Trial 211 finished with value: 0.5113335999999999 and parameters: {'learning_rate': 0.9934790342474772, 'max_depth': 9, 'min_child_weight': 6, 'gamma': 1.6757297309145747, 'reg_alpha': 8.296778899419863, 'reg_lambda': 7.770886469024282, 'subsample': 0.7178089696041026, 'colsample_bytree': 0.8875146419200994, 'colsample_bylevel': 0.7768515548848962, 'colsample_bynode': 0.6766028580312564, 'max_delta_step': 10, 'scale_pos_weight': 4}. Best is trial 178 with value: 0.5387142.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Builds\\\\20210426_T001818_German_data_fin\\\\study.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRIALS = None\n",
    "TIME_OUT = 60 * 2  # minutes\n",
    "N_JOBS = -1\n",
    "\n",
    "try:\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, BUILD_NAME),\n",
    "        n_trials=TRIALS,\n",
    "        timeout=TIME_OUT,\n",
    "        n_jobs=N_JOBS,\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    joblib.dump(study, os.path.join(\"Builds\", BUILD_NAME, \"study.pkl\"))\n",
    "\n",
    "joblib.dump(study, os.path.join(\"Builds\", BUILD_NAME, \"study.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD_NAME = \"20210425_T232957_German_data_fin\"\n",
    "# study = joblib.load(os.path.join(\"Builds\", BUILD_NAME, \"study.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5387142]\n",
      "{'learning_rate': 0.3208371150697334, 'max_depth': 14, 'min_child_weight': 8, 'gamma': 0.7710546555883082, 'reg_alpha': 6.363149955199062, 'reg_lambda': 0.5434369357798852, 'subsample': 0.7830182955045133, 'colsample_bytree': 0.820911303385816, 'colsample_bylevel': 0.7749767494583143, 'colsample_bynode': 0.6886742024787154, 'max_delta_step': 3, 'scale_pos_weight': 3, 'n_estimators': 41}\n"
     ]
    }
   ],
   "source": [
    "N = 178\n",
    "param = study.trials[N].params\n",
    "param[\"n_estimators\"] = study.trials[N].user_attrs[\"n_estimators\"]\n",
    "\n",
    "print(study.trials[N].values)\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(**param, eval_metric=\"auc\")\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=42)\n",
    "scores = cross_validate(\n",
    "    model, X[final_variables], np.ravel(y), scoring=\"roc_auc\", cv=cv, return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINI train: 0.631\n",
      "GINI dev: 0.517 (0.046)\n"
     ]
    }
   ],
   "source": [
    "mean_train_auc = scores[\"train_score\"].mean()\n",
    "mean_test_auc = scores[\"test_score\"].mean()\n",
    "std_test_auc = scores[\"test_score\"].std()\n",
    "print(\"GINI train:\", np.round(mean_train_auc * 2 - 1, 3))\n",
    "print(\"GINI dev:\", np.round(mean_test_auc * 2 - 1, 3), f\"({np.round(std_test_auc, 3)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script --no-prompt MultObject01.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
